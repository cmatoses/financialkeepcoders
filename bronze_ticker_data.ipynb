{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from google.cloud import bigquery\n",
    "from google.oauth2 import service_account\n",
    "from google.cloud import bigquery\n",
    "from google.cloud.exceptions import NotFound\n",
    "import pandas as pd\n",
    "import yahoo_fin.stock_info as si\n",
    "from utils.utils_bigquery import *\n",
    "from datetime import *\n",
    "import hashlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_path = key_path\n",
    "project = project_id\n",
    "dataset = 'bronze'\n",
    "table = 'bronze_ticker_data'\n",
    "table_conca = f'{project}.{dataset}.{table}'\n",
    "\n",
    "# schema = [\n",
    "#     {'name': 'dd', 'type': 'STRING'},\n",
    "#     {'name': 'date', 'type': 'DATE'},\n",
    "#     {'name': 'ticker', 'type': 'STRING'},\n",
    "#     {'name': 'adj close', 'type': 'INTEGER'},\n",
    "#     {'name': 'close', 'type': 'INTEGER'},\n",
    "#     {'name': 'high', 'type': 'INTEGER'},\n",
    "#     {'name': 'low', 'type': 'INTEGER'},\n",
    "#     {'name': 'Open', 'type': 'INTEGER'},\n",
    "#     {'name': 'Volume', 'type': 'INTEGER'},\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conectamos con Bigquery\n",
    "bigquery = BigQueryUtils(key_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>COP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EOG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>OXY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FANG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>TTWO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>GOOGL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>GOOG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>META</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>MTCH</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>503 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    ticker\n",
       "0      COP\n",
       "1      EOG\n",
       "2      OXY\n",
       "3      HES\n",
       "4     FANG\n",
       "..     ...\n",
       "498   TTWO\n",
       "499  GOOGL\n",
       "500   GOOG\n",
       "501   META\n",
       "502   MTCH\n",
       "\n",
       "[503 rows x 1 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_tickers = bigquery.run_query(\n",
    "    f\"\"\"\n",
    "    SELECT\n",
    "        ticker\n",
    "    FROM sara-carles-keepcoding.bronze.bronze_sp500_tickers\n",
    "    \"\"\"\n",
    ")\n",
    "unique_tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign an initial date to each ticker.\n",
    "unique_tickers_initial_date = initial_date_by_ticker(unique_tickers, initial_date='2015-01-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     ticker       date\n",
      "0      AAPL 2024-08-13\n",
      "1      AMGN 2024-08-13\n",
      "2      AMZN 2024-08-13\n",
      "3       AXP 2024-08-13\n",
      "4        BA 2024-08-13\n",
      "...     ...        ...\n",
      "4446  PDYNW 2024-08-13\n",
      "4447  PGYWW 2024-08-13\n",
      "4448  RENEW 2024-08-13\n",
      "4449  AIMAW 2024-08-12\n",
      "4450  BAERW 2024-08-12\n",
      "\n",
      "[4451 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Attempt to fetch the maximum date per ticker from BigQuery; fallback to initial dates if an error occurs.\n",
    "try:\n",
    "    max_date_by_ticker = bigquery.run_query(\n",
    "        f\"\"\"\n",
    "        SELECT\n",
    "            ticker,\n",
    "            max(date) as date \n",
    "        FROM {table_conca} \n",
    "        GROUP BY \n",
    "            ticker\n",
    "        \"\"\"\n",
    "    )\n",
    "    max_date_by_ticker['date'] = pd.to_datetime(max_date_by_ticker['date'])\n",
    "    max_date_by_ticker['date'] = max_date_by_ticker['date'].dt.tz_localize(None)\n",
    "    print(max_date_by_ticker)\n",
    "\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    max_date_by_ticker = unique_tickers_initial_date\n",
    "    print(max_date_by_ticker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>COP</td>\n",
       "      <td>2015-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EOG</td>\n",
       "      <td>2015-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>OXY</td>\n",
       "      <td>2015-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HES</td>\n",
       "      <td>2015-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FANG</td>\n",
       "      <td>2024-08-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>TTWO</td>\n",
       "      <td>2024-08-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>GOOGL</td>\n",
       "      <td>2024-08-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>GOOG</td>\n",
       "      <td>2024-08-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>META</td>\n",
       "      <td>2024-08-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>MTCH</td>\n",
       "      <td>2024-08-13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>503 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    ticker       date\n",
       "0      COP 2015-01-01\n",
       "1      EOG 2015-01-01\n",
       "2      OXY 2015-01-01\n",
       "3      HES 2015-01-01\n",
       "4     FANG 2024-08-13\n",
       "..     ...        ...\n",
       "498   TTWO 2024-08-13\n",
       "499  GOOGL 2024-08-13\n",
       "500   GOOG 2024-08-13\n",
       "501   META 2024-08-13\n",
       "502   MTCH 2024-08-13\n",
       "\n",
       "[503 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge with the DataFrame of unique tickers\n",
    "max_date_by_ticker = pd.merge(unique_tickers_initial_date, max_date_by_ticker, how='left', on='ticker')\n",
    "\n",
    "# Keep the maximum date between both fields\n",
    "max_date_by_ticker['date'] = max_date_by_ticker[['date', 'initial_date']].max(axis=1)\n",
    "\n",
    "# Remove the auxiliary 'initial_date' column\n",
    "max_date_by_ticker.drop(columns=['initial_date'], inplace=True)\n",
    "\n",
    "max_date_by_ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos obtenidos para COP.\n",
      "Datos obtenidos para EOG.\n",
      "Datos obtenidos para OXY.\n",
      "Datos obtenidos para HES.\n",
      "Datos obtenidos para FANG.\n",
      "Datos obtenidos para DVN.\n",
      "Datos obtenidos para EQT.\n",
      "Datos obtenidos para CTRA.\n",
      "Datos obtenidos para MRO.\n",
      "Datos obtenidos para APA.\n",
      "Datos obtenidos para WMB.\n",
      "Datos obtenidos para OKE.\n",
      "Datos obtenidos para KMI.\n",
      "Datos obtenidos para TRGP.\n",
      "Datos obtenidos para XOM.\n",
      "Datos obtenidos para CVX.\n",
      "Datos obtenidos para SLB.\n",
      "Datos obtenidos para BKR.\n",
      "Datos obtenidos para HAL.\n",
      "Datos obtenidos para MPC.\n",
      "Datos obtenidos para PSX.\n",
      "Datos obtenidos para VLO.\n",
      "Datos obtenidos para CEG.\n",
      "Datos obtenidos para GEV.\n",
      "Datos obtenidos para SRE.\n",
      "Datos obtenidos para AES.\n",
      "Datos obtenidos para ATO.\n",
      "Datos obtenidos para NI.\n",
      "Datos obtenidos para AWK.\n",
      "Datos obtenidos para NEE.\n",
      "Datos obtenidos para SO.\n",
      "Datos obtenidos para DUK.\n",
      "Datos obtenidos para AEP.\n",
      "Datos obtenidos para PCG.\n",
      "Datos obtenidos para D.\n",
      "Datos obtenidos para PEG.\n",
      "Datos obtenidos para EXC.\n",
      "Datos obtenidos para ED.\n",
      "Datos obtenidos para XEL.\n",
      "Datos obtenidos para EIX.\n",
      "Datos obtenidos para WEC.\n",
      "Datos obtenidos para DTE.\n",
      "Datos obtenidos para ETR.\n",
      "Datos obtenidos para FE.\n",
      "Datos obtenidos para ES.\n",
      "Datos obtenidos para PPL.\n",
      "Datos obtenidos para AEE.\n",
      "Datos obtenidos para CMS.\n",
      "Datos obtenidos para CNP.\n",
      "Datos obtenidos para LNT.\n",
      "Datos obtenidos para EVRG.\n",
      "Datos obtenidos para PNW.\n",
      "Datos obtenidos para VST.\n",
      "Datos obtenidos para NRG.\n",
      "Datos obtenidos para REGN.\n",
      "Datos obtenidos para VRTX.\n",
      "Datos obtenidos para MRNA.\n",
      "Datos obtenidos para INCY.\n",
      "Datos obtenidos para TECH.\n",
      "Datos obtenidos para ABT.\n",
      "Datos obtenidos para SYK.\n",
      "Datos obtenidos para BSX.\n",
      "Datos obtenidos para MDT.\n",
      "Datos obtenidos para EW.\n",
      "Datos obtenidos para DXCM.\n",
      "Datos obtenidos para STE.\n",
      "Datos obtenidos para ZBH.\n",
      "Datos obtenidos para PODD.\n",
      "Datos obtenidos para BIO.\n",
      "Datos obtenidos para UNH.\n",
      "Datos obtenidos para ELV.\n",
      "Datos obtenidos para CI.\n",
      "Datos obtenidos para CVS.\n",
      "Datos obtenidos para HUM.\n",
      "Datos obtenidos para CNC.\n",
      "Datos obtenidos para MOH.\n",
      "Datos obtenidos para MCK.\n",
      "Datos obtenidos para COR.\n",
      "Datos obtenidos para CAH.\n",
      "Datos obtenidos para HSIC.\n",
      "Datos obtenidos para TMO.\n",
      "Datos obtenidos para DHR.\n",
      "Datos obtenidos para IQV.\n",
      "Datos obtenidos para A.\n",
      "Datos obtenidos para IDXX.\n",
      "Datos obtenidos para MTD.\n",
      "Datos obtenidos para WAT.\n",
      "Datos obtenidos para LH.\n",
      "Datos obtenidos para DGX.\n",
      "Datos obtenidos para RVTY.\n",
      "Datos obtenidos para CRL.\n",
      "Datos obtenidos para HCA.\n",
      "Datos obtenidos para UHS.\n",
      "Datos obtenidos para DVA.\n",
      "Datos obtenidos para WBA.\n",
      "Datos obtenidos para GEHC.\n",
      "Datos obtenidos para SOLV.\n",
      "Datos obtenidos para LLY.\n",
      "Datos obtenidos para JNJ.\n",
      "Datos obtenidos para ABBV.\n",
      "Datos obtenidos para MRK.\n",
      "Datos obtenidos para AMGN.\n",
      "Datos obtenidos para PFE.\n",
      "Datos obtenidos para BMY.\n",
      "Datos obtenidos para GILD.\n",
      "Datos obtenidos para BIIB.\n",
      "Datos obtenidos para ISRG.\n",
      "Datos obtenidos para BDX.\n",
      "Datos obtenidos para RMD.\n",
      "Datos obtenidos para WST.\n",
      "Datos obtenidos para COO.\n",
      "Datos obtenidos para HOLX.\n",
      "Datos obtenidos para BAX.\n",
      "Datos obtenidos para ALGN.\n",
      "Datos obtenidos para TFX.\n",
      "Datos obtenidos para ZTS.\n",
      "Datos obtenidos para VTRS.\n",
      "Datos obtenidos para CTLT.\n",
      "Datos obtenidos para FSLR.\n",
      "Datos obtenidos para ENPH.\n",
      "Datos obtenidos para NVDA.\n",
      "Datos obtenidos para AVGO.\n",
      "Datos obtenidos para AMD.\n",
      "Datos obtenidos para QCOM.\n",
      "Datos obtenidos para TXN.\n",
      "Datos obtenidos para MU.\n",
      "Datos obtenidos para ADI.\n",
      "Datos obtenidos para INTC.\n",
      "Datos obtenidos para NXPI.\n",
      "Datos obtenidos para MPWR.\n",
      "Datos obtenidos para MCHP.\n",
      "Datos obtenidos para ON.\n",
      "Datos obtenidos para SWKS.\n",
      "Datos obtenidos para QRVO.\n",
      "Datos obtenidos para ANET.\n",
      "Datos obtenidos para SMCI.\n",
      "Datos obtenidos para HPQ.\n",
      "Datos obtenidos para NTAP.\n",
      "Datos obtenidos para STX.\n",
      "Datos obtenidos para WDC.\n",
      "Datos obtenidos para AAPL.\n",
      "Datos obtenidos para APH.\n",
      "Datos obtenidos para TEL.\n",
      "Datos obtenidos para GLW.\n",
      "Datos obtenidos para JBL.\n",
      "Datos obtenidos para CRM.\n",
      "Datos obtenidos para INTU.\n",
      "Datos obtenidos para NOW.\n",
      "Datos obtenidos para UBER.\n",
      "Datos obtenidos para ADP.\n",
      "Datos obtenidos para CDNS.\n",
      "Datos obtenidos para ROP.\n",
      "Datos obtenidos para ADSK.\n",
      "Datos obtenidos para PAYX.\n",
      "Datos obtenidos para FICO.\n",
      "Datos obtenidos para ANSS.\n",
      "Datos obtenidos para TYL.\n",
      "Datos obtenidos para PTC.\n",
      "Datos obtenidos para PAYC.\n",
      "Datos obtenidos para DAY.\n",
      "Datos obtenidos para CSCO.\n",
      "Datos obtenidos para MSI.\n",
      "Datos obtenidos para HPE.\n",
      "Datos obtenidos para ZBRA.\n",
      "Datos obtenidos para JNPR.\n",
      "Datos obtenidos para MSFT.\n",
      "Datos obtenidos para ORCL.\n",
      "Datos obtenidos para ADBE.\n",
      "Datos obtenidos para PANW.\n",
      "Datos obtenidos para SNPS.\n",
      "Datos obtenidos para CRWD.\n",
      "Datos obtenidos para FTNT.\n",
      "Datos obtenidos para GDDY.\n",
      "Datos obtenidos para CPAY.\n",
      "Datos obtenidos para VRSN.\n",
      "Datos obtenidos para GEN.\n",
      "Datos obtenidos para AKAM.\n",
      "Datos obtenidos para FFIV.\n",
      "Datos obtenidos para ACN.\n",
      "Datos obtenidos para IBM.\n",
      "Datos obtenidos para FI.\n",
      "Datos obtenidos para FIS.\n",
      "Datos obtenidos para CTSH.\n",
      "Datos obtenidos para IT.\n",
      "Datos obtenidos para CDW.\n",
      "Datos obtenidos para BR.\n",
      "Datos obtenidos para LDOS.\n",
      "Datos obtenidos para JKHY.\n",
      "Datos obtenidos para EPAM.\n",
      "Datos obtenidos para GRMN.\n",
      "Datos obtenidos para FTV.\n",
      "Datos obtenidos para KEYS.\n",
      "Datos obtenidos para TDY.\n",
      "Datos obtenidos para TRMB.\n",
      "Datos obtenidos para AMAT.\n",
      "Datos obtenidos para LRCX.\n",
      "Datos obtenidos para KLAC.\n",
      "Datos obtenidos para TER.\n",
      "Datos obtenidos para DAL.\n",
      "Datos obtenidos para LUV.\n",
      "Datos obtenidos para UAL.\n",
      "Datos obtenidos para AAL.\n",
      "Datos obtenidos para ODFL.\n",
      "Datos obtenidos para UNP.\n",
      "Datos obtenidos para CSX.\n",
      "Datos obtenidos para NSC.\n",
      "Datos obtenidos para WAB.\n",
      "Datos obtenidos para HON.\n",
      "Datos obtenidos para MMM.\n",
      "Datos obtenidos para WM.\n",
      "Datos obtenidos para RSG.\n",
      "Datos obtenidos para GE.\n",
      "Datos obtenidos para RTX.\n",
      "Datos obtenidos para LMT.\n",
      "Datos obtenidos para BA.\n",
      "Datos obtenidos para GD.\n",
      "Datos obtenidos para NOC.\n",
      "Datos obtenidos para TDG.\n",
      "Datos obtenidos para LHX.\n",
      "Datos obtenidos para HWM.\n",
      "Datos obtenidos para AXON.\n",
      "Datos obtenidos para TXT.\n",
      "Datos obtenidos para HII.\n",
      "Datos obtenidos para VRSK.\n",
      "Datos obtenidos para EFX.\n",
      "Datos obtenidos para SWK.\n",
      "Datos obtenidos para SNA.\n",
      "Datos obtenidos para GWW.\n",
      "Datos obtenidos para FAST.\n",
      "Datos obtenidos para POOL.\n",
      "Datos obtenidos para URI.\n",
      "Datos obtenidos para PWR.\n",
      "Datos obtenidos para J.\n",
      "Datos obtenidos para CTAS.\n",
      "Datos obtenidos para CPRT.\n",
      "Datos obtenidos para GPN.\n",
      "Datos obtenidos para HUBB.\n",
      "Datos obtenidos para TT.\n",
      "Datos obtenidos para CARR.\n",
      "Datos obtenidos para JCI.\n",
      "Datos obtenidos para BLDR.\n",
      "Datos obtenidos para MAS.\n",
      "Datos obtenidos para UPS.\n",
      "Datos obtenidos para FDX.\n",
      "Datos obtenidos para JBHT.\n",
      "Datos obtenidos para EXPD.\n",
      "Datos obtenidos para CHRW.\n",
      "Datos obtenidos para VLTO.\n",
      "Datos obtenidos para ALLE.\n",
      "Datos obtenidos para ETN.\n",
      "Datos obtenidos para PH.\n",
      "Datos obtenidos para ITW.\n",
      "Datos obtenidos para EMR.\n",
      "Datos obtenidos para CMI.\n",
      "Datos obtenidos para AME.\n",
      "Datos obtenidos para OTIS.\n",
      "Datos obtenidos para IR.\n",
      "Datos obtenidos para XYL.\n",
      "Datos obtenidos para ROK.\n",
      "Datos obtenidos para DOV.\n",
      "Datos obtenidos para IEX.\n",
      "Datos obtenidos para PNR.\n",
      "Datos obtenidos para NDSN.\n",
      "Datos obtenidos para AOS.\n",
      "Datos obtenidos para GNRC.\n",
      "Datos obtenidos para CAT.\n",
      "Datos obtenidos para DE.\n",
      "Datos obtenidos para PCAR.\n",
      "Datos obtenidos para ARE.\n",
      "Datos obtenidos para BXP.\n",
      "Datos obtenidos para SPG.\n",
      "Datos obtenidos para O.\n",
      "Datos obtenidos para KIM.\n",
      "Datos obtenidos para REG.\n",
      "Datos obtenidos para FRT.\n",
      "Datos obtenidos para AMT.\n",
      "Datos obtenidos para EQIX.\n",
      "Datos obtenidos para DLR.\n",
      "Datos obtenidos para CCI.\n",
      "Datos obtenidos para IRM.\n",
      "Datos obtenidos para SBAC.\n",
      "Datos obtenidos para WY.\n",
      "Datos obtenidos para PLD.\n",
      "Datos obtenidos para PSA.\n",
      "Datos obtenidos para EXR.\n",
      "Datos obtenidos para VICI.\n",
      "Datos obtenidos para AVB.\n",
      "Datos obtenidos para EQR.\n",
      "Datos obtenidos para INVH.\n",
      "Datos obtenidos para ESS.\n",
      "Datos obtenidos para MAA.\n",
      "Datos obtenidos para UDR.\n",
      "Datos obtenidos para CPT.\n",
      "Datos obtenidos para HST.\n",
      "Datos obtenidos para CBRE.\n",
      "Datos obtenidos para CSGP.\n",
      "Datos obtenidos para WELL.\n",
      "Datos obtenidos para VTR.\n",
      "Datos obtenidos para DOC.\n",
      "Datos obtenidos para NEM.\n",
      "Datos obtenidos para NUE.\n",
      "Datos obtenidos para STLD.\n",
      "Datos obtenidos para FCX.\n",
      "Datos obtenidos para DOW.\n",
      "Datos obtenidos para CE.\n",
      "Datos obtenidos para MLM.\n",
      "Datos obtenidos para VMC.\n",
      "Datos obtenidos para CTVA.\n",
      "Datos obtenidos para CF.\n",
      "Datos obtenidos para MOS.\n",
      "Datos obtenidos para FMC.\n",
      "Datos obtenidos para LIN.\n",
      "Datos obtenidos para SHW.\n",
      "Datos obtenidos para ECL.\n",
      "Datos obtenidos para APD.\n",
      "Datos obtenidos para DD.\n",
      "Datos obtenidos para LYB.\n",
      "Datos obtenidos para PPG.\n",
      "Datos obtenidos para IFF.\n",
      "Datos obtenidos para EMN.\n",
      "Datos obtenidos para ALB.\n",
      "Datos obtenidos para HAS.\n",
      "Datos obtenidos para MAR.\n",
      "Datos obtenidos para HLT.\n",
      "Datos obtenidos para GPC.\n",
      "Datos obtenidos para APTV.\n",
      "Datos obtenidos para LKQ.\n",
      "Datos obtenidos para BWA.\n",
      "Datos obtenidos para MCD.\n",
      "Datos obtenidos para SBUX.\n",
      "Datos obtenidos para CMG.\n",
      "Datos obtenidos para YUM.\n",
      "Datos obtenidos para DRI.\n",
      "Datos obtenidos para DPZ.\n",
      "Datos obtenidos para TPR.\n",
      "Datos obtenidos para TJX.\n",
      "Datos obtenidos para ROST.\n",
      "Datos obtenidos para LULU.\n",
      "Datos obtenidos para AMZN.\n",
      "Datos obtenidos para EBAY.\n",
      "Datos obtenidos para ETSY.\n",
      "Datos obtenidos para BKNG.\n",
      "Datos obtenidos para ABNB.\n",
      "Datos obtenidos para RCL.\n",
      "Datos obtenidos para CCL.\n",
      "Datos obtenidos para EXPE.\n",
      "Datos obtenidos para NCLH.\n",
      "Datos obtenidos para ORLY.\n",
      "Datos obtenidos para AZO.\n",
      "Datos obtenidos para TSCO.\n",
      "Datos obtenidos para BBY.\n",
      "Datos obtenidos para ULTA.\n",
      "Datos obtenidos para BBWI.\n",
      "Datos obtenidos para ROL.\n",
      "Datos obtenidos para LVS.\n",
      "Datos obtenidos para MGM.\n",
      "Datos obtenidos para WYNN.\n",
      "Datos obtenidos para CZR.\n",
      "Datos obtenidos para TSLA.\n",
      "Datos obtenidos para GM.\n",
      "Datos obtenidos para F.\n",
      "Datos obtenidos para RL.\n",
      "Datos obtenidos para NKE.\n",
      "Datos obtenidos para DECK.\n",
      "Datos obtenidos para SW.\n",
      "Datos obtenidos para BALL.\n",
      "Datos obtenidos para PKG.\n",
      "Datos obtenidos para AVY.\n",
      "Datos obtenidos para IP.\n",
      "Datos obtenidos para AMCR.\n",
      "Datos obtenidos para HD.\n",
      "Datos obtenidos para LOW.\n",
      "Datos obtenidos para KMX.\n",
      "Datos obtenidos para DHI.\n",
      "Datos obtenidos para LEN.\n",
      "Datos obtenidos para NVR.\n",
      "Datos obtenidos para PHM.\n",
      "Datos obtenidos para MHK.\n",
      "Datos obtenidos para PM.\n",
      "Datos obtenidos para MO.\n",
      "Datos obtenidos para MDLZ.\n",
      "Datos obtenidos para HSY.\n",
      "Datos obtenidos para ADM.\n",
      "Datos obtenidos para TSN.\n",
      "Datos obtenidos para BG.\n",
      "Datos obtenidos para KR.\n",
      "Datos obtenidos para KHC.\n",
      "Datos obtenidos para GIS.\n",
      "Datos obtenidos para K.\n",
      "Datos obtenidos para MKC.\n",
      "Datos obtenidos para HRL.\n",
      "Datos obtenidos para CPB.\n",
      "Datos obtenidos para CAG.\n",
      "Datos obtenidos para SJM.\n",
      "Datos obtenidos para LW.\n",
      "Datos obtenidos para WMT.\n",
      "Datos obtenidos para COST.\n",
      "Datos obtenidos para TGT.\n",
      "Datos obtenidos para DG.\n",
      "Datos obtenidos para DLTR.\n",
      "Datos obtenidos para SYY.\n",
      "Datos obtenidos para STZ.\n",
      "Datos obtenidos para TAP.\n",
      "Datos obtenidos para KO.\n",
      "Datos obtenidos para PEP.\n",
      "Datos obtenidos para KDP.\n",
      "Datos obtenidos para MNST.\n",
      "Datos obtenidos para PG.\n",
      "Datos obtenidos para CL.\n",
      "Datos obtenidos para KMB.\n",
      "Datos obtenidos para KVUE.\n",
      "Datos obtenidos para EL.\n",
      "Datos obtenidos para CHD.\n",
      "Datos obtenidos para CLX.\n",
      "Datos obtenidos para BF-B.\n",
      "Datos obtenidos para MS.\n",
      "Datos obtenidos para GS.\n",
      "Datos obtenidos para SCHW.\n",
      "Datos obtenidos para MKTX.\n",
      "Datos obtenidos para V.\n",
      "Datos obtenidos para MA.\n",
      "Datos obtenidos para AXP.\n",
      "Datos obtenidos para PYPL.\n",
      "Datos obtenidos para COF.\n",
      "Datos obtenidos para DFS.\n",
      "Datos obtenidos para SYF.\n",
      "Datos obtenidos para BX.\n",
      "Datos obtenidos para BLK.\n",
      "Datos obtenidos para KKR.\n",
      "Datos obtenidos para BK.\n",
      "Datos obtenidos para AMP.\n",
      "Datos obtenidos para TROW.\n",
      "Datos obtenidos para STT.\n",
      "Datos obtenidos para RJF.\n",
      "Datos obtenidos para PFG.\n",
      "Datos obtenidos para NTRS.\n",
      "Datos obtenidos para BEN.\n",
      "Datos obtenidos para IVZ.\n",
      "Datos obtenidos para PNC.\n",
      "Datos obtenidos para USB.\n",
      "Datos obtenidos para TFC.\n",
      "Datos obtenidos para FITB.\n",
      "Datos obtenidos para MTB.\n",
      "Datos obtenidos para HBAN.\n",
      "Datos obtenidos para RF.\n",
      "Datos obtenidos para CFG.\n",
      "Datos obtenidos para KEY.\n",
      "Datos obtenidos para AFL.\n",
      "Datos obtenidos para MET.\n",
      "Datos obtenidos para PRU.\n",
      "Datos obtenidos para GL.\n",
      "Datos obtenidos para MMC.\n",
      "Datos obtenidos para AON.\n",
      "Datos obtenidos para AJG.\n",
      "Datos obtenidos para BRO.\n",
      "Datos obtenidos para WTW.\n",
      "Datos obtenidos para JPM.\n",
      "Datos obtenidos para BAC.\n",
      "Datos obtenidos para WFC.\n",
      "Datos obtenidos para C.\n",
      "Datos obtenidos para AIZ.\n",
      "Datos obtenidos para BRK-B.\n",
      "Datos obtenidos para AIG.\n",
      "Datos obtenidos para ACGL.\n",
      "Datos obtenidos para EG.\n",
      "Datos obtenidos para PGR.\n",
      "Datos obtenidos para CB.\n",
      "Datos obtenidos para TRV.\n",
      "Datos obtenidos para ALL.\n",
      "Datos obtenidos para HIG.\n",
      "Datos obtenidos para WRB.\n",
      "Datos obtenidos para CINF.\n",
      "Datos obtenidos para L.\n",
      "Datos obtenidos para SPGI.\n",
      "Datos obtenidos para ICE.\n",
      "Datos obtenidos para MCO.\n",
      "Datos obtenidos para CME.\n",
      "Datos obtenidos para MSCI.\n",
      "Datos obtenidos para NDAQ.\n",
      "Datos obtenidos para CBOE.\n",
      "Datos obtenidos para FDS.\n",
      "Datos obtenidos para NFLX.\n",
      "Datos obtenidos para DIS.\n",
      "Datos obtenidos para LYV.\n",
      "Datos obtenidos para WBD.\n",
      "Datos obtenidos para FOXA.\n",
      "Datos obtenidos para FOX.\n",
      "Datos obtenidos para NWS.\n",
      "Datos obtenidos para NWSA.\n",
      "Datos obtenidos para PARA.\n",
      "Datos obtenidos para TMUS.\n",
      "Datos obtenidos para VZ.\n",
      "Datos obtenidos para CMCSA.\n",
      "Datos obtenidos para T.\n",
      "Datos obtenidos para CHTR.\n",
      "Datos obtenidos para OMC.\n",
      "Datos obtenidos para IPG.\n",
      "Datos obtenidos para EA.\n",
      "Datos obtenidos para TTWO.\n",
      "Datos obtenidos para GOOGL.\n",
      "Datos obtenidos para GOOG.\n",
      "Datos obtenidos para META.\n",
      "Datos obtenidos para MTCH.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>adjclose</th>\n",
       "      <th>volume</th>\n",
       "      <th>ticker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>68.500000</td>\n",
       "      <td>69.480003</td>\n",
       "      <td>68.230003</td>\n",
       "      <td>68.919998</td>\n",
       "      <td>50.309769</td>\n",
       "      <td>5701800</td>\n",
       "      <td>COP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>67.709999</td>\n",
       "      <td>67.980003</td>\n",
       "      <td>65.430000</td>\n",
       "      <td>65.639999</td>\n",
       "      <td>47.915482</td>\n",
       "      <td>10938900</td>\n",
       "      <td>COP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-06</td>\n",
       "      <td>65.290001</td>\n",
       "      <td>66.599998</td>\n",
       "      <td>62.880001</td>\n",
       "      <td>62.930000</td>\n",
       "      <td>45.937244</td>\n",
       "      <td>18054700</td>\n",
       "      <td>COP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-07</td>\n",
       "      <td>64.010002</td>\n",
       "      <td>64.230003</td>\n",
       "      <td>62.849998</td>\n",
       "      <td>63.349998</td>\n",
       "      <td>46.243835</td>\n",
       "      <td>12350500</td>\n",
       "      <td>COP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-08</td>\n",
       "      <td>64.849998</td>\n",
       "      <td>65.489998</td>\n",
       "      <td>63.900002</td>\n",
       "      <td>64.930000</td>\n",
       "      <td>47.397194</td>\n",
       "      <td>10348300</td>\n",
       "      <td>COP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>776567</th>\n",
       "      <td>2024-08-19</td>\n",
       "      <td>34.910000</td>\n",
       "      <td>36.700001</td>\n",
       "      <td>34.910000</td>\n",
       "      <td>36.580002</td>\n",
       "      <td>36.580002</td>\n",
       "      <td>3884700</td>\n",
       "      <td>MTCH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>776568</th>\n",
       "      <td>2024-08-20</td>\n",
       "      <td>36.360001</td>\n",
       "      <td>36.595001</td>\n",
       "      <td>36.169998</td>\n",
       "      <td>36.529999</td>\n",
       "      <td>36.529999</td>\n",
       "      <td>3375900</td>\n",
       "      <td>MTCH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>776569</th>\n",
       "      <td>2024-08-21</td>\n",
       "      <td>36.689999</td>\n",
       "      <td>37.580002</td>\n",
       "      <td>36.439999</td>\n",
       "      <td>37.139999</td>\n",
       "      <td>37.139999</td>\n",
       "      <td>4550400</td>\n",
       "      <td>MTCH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>776570</th>\n",
       "      <td>2024-08-22</td>\n",
       "      <td>37.099998</td>\n",
       "      <td>37.160000</td>\n",
       "      <td>36.360001</td>\n",
       "      <td>36.419998</td>\n",
       "      <td>36.419998</td>\n",
       "      <td>4800500</td>\n",
       "      <td>MTCH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>776571</th>\n",
       "      <td>2024-08-23</td>\n",
       "      <td>36.669998</td>\n",
       "      <td>37.424999</td>\n",
       "      <td>36.590000</td>\n",
       "      <td>37.320000</td>\n",
       "      <td>37.320000</td>\n",
       "      <td>5294400</td>\n",
       "      <td>MTCH</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>776572 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             date       open       high        low      close   adjclose  \\\n",
       "0      2015-01-02  68.500000  69.480003  68.230003  68.919998  50.309769   \n",
       "1      2015-01-05  67.709999  67.980003  65.430000  65.639999  47.915482   \n",
       "2      2015-01-06  65.290001  66.599998  62.880001  62.930000  45.937244   \n",
       "3      2015-01-07  64.010002  64.230003  62.849998  63.349998  46.243835   \n",
       "4      2015-01-08  64.849998  65.489998  63.900002  64.930000  47.397194   \n",
       "...           ...        ...        ...        ...        ...        ...   \n",
       "776567 2024-08-19  34.910000  36.700001  34.910000  36.580002  36.580002   \n",
       "776568 2024-08-20  36.360001  36.595001  36.169998  36.529999  36.529999   \n",
       "776569 2024-08-21  36.689999  37.580002  36.439999  37.139999  37.139999   \n",
       "776570 2024-08-22  37.099998  37.160000  36.360001  36.419998  36.419998   \n",
       "776571 2024-08-23  36.669998  37.424999  36.590000  37.320000  37.320000   \n",
       "\n",
       "          volume ticker  \n",
       "0        5701800    COP  \n",
       "1       10938900    COP  \n",
       "2       18054700    COP  \n",
       "3       12350500    COP  \n",
       "4       10348300    COP  \n",
       "...          ...    ...  \n",
       "776567   3884700   MTCH  \n",
       "776568   3375900   MTCH  \n",
       "776569   4550400   MTCH  \n",
       "776570   4800500   MTCH  \n",
       "776571   5294400   MTCH  \n",
       "\n",
       "[776572 rows x 8 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform an incremental update to fetch the latest records\n",
    "new_df = fetch_historical_data(max_date_by_ticker, start_date_col='date', interval='1d')\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>adjclose</th>\n",
       "      <th>volume</th>\n",
       "      <th>ticker</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>68.500000</td>\n",
       "      <td>69.480003</td>\n",
       "      <td>68.230003</td>\n",
       "      <td>68.919998</td>\n",
       "      <td>50.309769</td>\n",
       "      <td>5701800</td>\n",
       "      <td>COP</td>\n",
       "      <td>4342948b0ecbd3d9b2bd691bb3d0f45a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>67.709999</td>\n",
       "      <td>67.980003</td>\n",
       "      <td>65.430000</td>\n",
       "      <td>65.639999</td>\n",
       "      <td>47.915482</td>\n",
       "      <td>10938900</td>\n",
       "      <td>COP</td>\n",
       "      <td>8035c040b4c16aaae94334be92d773fd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-06</td>\n",
       "      <td>65.290001</td>\n",
       "      <td>66.599998</td>\n",
       "      <td>62.880001</td>\n",
       "      <td>62.930000</td>\n",
       "      <td>45.937244</td>\n",
       "      <td>18054700</td>\n",
       "      <td>COP</td>\n",
       "      <td>273e2f6115430f61fc8d6cfe366d260e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-07</td>\n",
       "      <td>64.010002</td>\n",
       "      <td>64.230003</td>\n",
       "      <td>62.849998</td>\n",
       "      <td>63.349998</td>\n",
       "      <td>46.243835</td>\n",
       "      <td>12350500</td>\n",
       "      <td>COP</td>\n",
       "      <td>4581c3e5a836782fddb2a4505e45fb66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-08</td>\n",
       "      <td>64.849998</td>\n",
       "      <td>65.489998</td>\n",
       "      <td>63.900002</td>\n",
       "      <td>64.930000</td>\n",
       "      <td>47.397194</td>\n",
       "      <td>10348300</td>\n",
       "      <td>COP</td>\n",
       "      <td>2475f7a4282d8fdbe55aefd82b119046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>776567</th>\n",
       "      <td>2024-08-19</td>\n",
       "      <td>34.910000</td>\n",
       "      <td>36.700001</td>\n",
       "      <td>34.910000</td>\n",
       "      <td>36.580002</td>\n",
       "      <td>36.580002</td>\n",
       "      <td>3884700</td>\n",
       "      <td>MTCH</td>\n",
       "      <td>cd0484f31059c8724b858370c1dc9b8f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>776568</th>\n",
       "      <td>2024-08-20</td>\n",
       "      <td>36.360001</td>\n",
       "      <td>36.595001</td>\n",
       "      <td>36.169998</td>\n",
       "      <td>36.529999</td>\n",
       "      <td>36.529999</td>\n",
       "      <td>3375900</td>\n",
       "      <td>MTCH</td>\n",
       "      <td>d7b903d7ef9849e21d50e60813dbfebd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>776569</th>\n",
       "      <td>2024-08-21</td>\n",
       "      <td>36.689999</td>\n",
       "      <td>37.580002</td>\n",
       "      <td>36.439999</td>\n",
       "      <td>37.139999</td>\n",
       "      <td>37.139999</td>\n",
       "      <td>4550400</td>\n",
       "      <td>MTCH</td>\n",
       "      <td>c2e2f3489b2be3381ced46016e4ed21d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>776570</th>\n",
       "      <td>2024-08-22</td>\n",
       "      <td>37.099998</td>\n",
       "      <td>37.160000</td>\n",
       "      <td>36.360001</td>\n",
       "      <td>36.419998</td>\n",
       "      <td>36.419998</td>\n",
       "      <td>4800500</td>\n",
       "      <td>MTCH</td>\n",
       "      <td>7ff4851947e5aec2c4f32365c70f10a3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>776571</th>\n",
       "      <td>2024-08-23</td>\n",
       "      <td>36.669998</td>\n",
       "      <td>37.424999</td>\n",
       "      <td>36.590000</td>\n",
       "      <td>37.320000</td>\n",
       "      <td>37.320000</td>\n",
       "      <td>5294400</td>\n",
       "      <td>MTCH</td>\n",
       "      <td>faf5ba60eccd06b480f997a4023d62a0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>776572 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             date       open       high        low      close   adjclose  \\\n",
       "0      2015-01-02  68.500000  69.480003  68.230003  68.919998  50.309769   \n",
       "1      2015-01-05  67.709999  67.980003  65.430000  65.639999  47.915482   \n",
       "2      2015-01-06  65.290001  66.599998  62.880001  62.930000  45.937244   \n",
       "3      2015-01-07  64.010002  64.230003  62.849998  63.349998  46.243835   \n",
       "4      2015-01-08  64.849998  65.489998  63.900002  64.930000  47.397194   \n",
       "...           ...        ...        ...        ...        ...        ...   \n",
       "776567 2024-08-19  34.910000  36.700001  34.910000  36.580002  36.580002   \n",
       "776568 2024-08-20  36.360001  36.595001  36.169998  36.529999  36.529999   \n",
       "776569 2024-08-21  36.689999  37.580002  36.439999  37.139999  37.139999   \n",
       "776570 2024-08-22  37.099998  37.160000  36.360001  36.419998  36.419998   \n",
       "776571 2024-08-23  36.669998  37.424999  36.590000  37.320000  37.320000   \n",
       "\n",
       "          volume ticker                                id  \n",
       "0        5701800    COP  4342948b0ecbd3d9b2bd691bb3d0f45a  \n",
       "1       10938900    COP  8035c040b4c16aaae94334be92d773fd  \n",
       "2       18054700    COP  273e2f6115430f61fc8d6cfe366d260e  \n",
       "3       12350500    COP  4581c3e5a836782fddb2a4505e45fb66  \n",
       "4       10348300    COP  2475f7a4282d8fdbe55aefd82b119046  \n",
       "...          ...    ...                               ...  \n",
       "776567   3884700   MTCH  cd0484f31059c8724b858370c1dc9b8f  \n",
       "776568   3375900   MTCH  d7b903d7ef9849e21d50e60813dbfebd  \n",
       "776569   4550400   MTCH  c2e2f3489b2be3381ced46016e4ed21d  \n",
       "776570   4800500   MTCH  7ff4851947e5aec2c4f32365c70f10a3  \n",
       "776571   5294400   MTCH  faf5ba60eccd06b480f997a4023d62a0  \n",
       "\n",
       "[776572 rows x 9 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fields that make up the ID\n",
    "id_fields = ['ticker', 'date']\n",
    "\n",
    "# Apply the function to the DataFrame to create the 'id' column\n",
    "new_df['id'] = new_df.apply(generate_id, axis=1, fields=id_fields)\n",
    "\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidSchema",
     "evalue": "Reason: Provided Schema does not match Table sara-carles-keepcoding:bronze.bronze_ticker_data. Cannot add fields (field: id)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;66;03m# Filtramos solamente los nuevos registros\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m     df_incremental \u001b[38;5;241m=\u001b[39m \u001b[43mselect_for_incremental\u001b[49m(\u001b[38;5;28mid\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m, table\u001b[38;5;241m=\u001b[39mtable_conca, new_df\u001b[38;5;241m=\u001b[39mnew_df)\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;66;03m# Guardamos los datos en bigquery\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'select_for_incremental' is not defined",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInvalidResponse\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\CARLES\\anaconda3\\envs\\financialkeepcoders\\lib\\site-packages\\google\\cloud\\bigquery\\client.py:2589\u001b[0m, in \u001b[0;36mClient.load_table_from_file\u001b[1;34m(self, file_obj, destination, rewind, size, num_retries, job_id, job_id_prefix, location, project, job_config, timeout)\u001b[0m\n\u001b[0;32m   2588\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m size \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m _MAX_MULTIPART_SIZE:\n\u001b[1;32m-> 2589\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_resumable_upload\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2590\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfile_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjob_resource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_retries\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproject\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproject\u001b[49m\n\u001b[0;32m   2591\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2592\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\CARLES\\anaconda3\\envs\\financialkeepcoders\\lib\\site-packages\\google\\cloud\\bigquery\\client.py:3009\u001b[0m, in \u001b[0;36mClient._do_resumable_upload\u001b[1;34m(self, stream, metadata, num_retries, timeout, project)\u001b[0m\n\u001b[0;32m   2986\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Perform a resumable upload.\u001b[39;00m\n\u001b[0;32m   2987\u001b[0m \n\u001b[0;32m   2988\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3007\u001b[0m \u001b[38;5;124;03m    is uploaded.\u001b[39;00m\n\u001b[0;32m   3008\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m-> 3009\u001b[0m upload, transport \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initiate_resumable_upload\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3010\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_retries\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproject\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproject\u001b[49m\n\u001b[0;32m   3011\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3013\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m upload\u001b[38;5;241m.\u001b[39mfinished:\n",
      "File \u001b[1;32mc:\\Users\\CARLES\\anaconda3\\envs\\financialkeepcoders\\lib\\site-packages\\google\\cloud\\bigquery\\client.py:3078\u001b[0m, in \u001b[0;36mClient._initiate_resumable_upload\u001b[1;34m(self, stream, metadata, num_retries, timeout, project)\u001b[0m\n\u001b[0;32m   3074\u001b[0m     upload\u001b[38;5;241m.\u001b[39m_retry_strategy \u001b[38;5;241m=\u001b[39m resumable_media\u001b[38;5;241m.\u001b[39mRetryStrategy(\n\u001b[0;32m   3075\u001b[0m         max_retries\u001b[38;5;241m=\u001b[39mnum_retries\n\u001b[0;32m   3076\u001b[0m     )\n\u001b[1;32m-> 3078\u001b[0m \u001b[43mupload\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minitiate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3079\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtransport\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3080\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3081\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3082\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_GENERIC_CONTENT_TYPE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3083\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_final\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   3084\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3085\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3087\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m upload, transport\n",
      "File \u001b[1;32mc:\\Users\\CARLES\\anaconda3\\envs\\financialkeepcoders\\lib\\site-packages\\google\\resumable_media\\requests\\upload.py:420\u001b[0m, in \u001b[0;36mResumableUpload.initiate\u001b[1;34m(self, transport, stream, metadata, content_type, total_bytes, stream_final, timeout)\u001b[0m\n\u001b[0;32m    418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[1;32m--> 420\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_request_helpers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait_and_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    421\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretriable_request\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_status_code\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_strategy\u001b[49m\n\u001b[0;32m    422\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\CARLES\\anaconda3\\envs\\financialkeepcoders\\lib\\site-packages\\google\\resumable_media\\requests\\_request_helpers.py:155\u001b[0m, in \u001b[0;36mwait_and_retry\u001b[1;34m(func, get_status_code, retry_strategy)\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 155\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _CONNECTION_ERROR_CLASSES \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\CARLES\\anaconda3\\envs\\financialkeepcoders\\lib\\site-packages\\google\\resumable_media\\requests\\upload.py:416\u001b[0m, in \u001b[0;36mResumableUpload.initiate.<locals>.retriable_request\u001b[1;34m()\u001b[0m\n\u001b[0;32m    412\u001b[0m result \u001b[38;5;241m=\u001b[39m transport\u001b[38;5;241m.\u001b[39mrequest(\n\u001b[0;32m    413\u001b[0m     method, url, data\u001b[38;5;241m=\u001b[39mpayload, headers\u001b[38;5;241m=\u001b[39mheaders, timeout\u001b[38;5;241m=\u001b[39mtimeout\n\u001b[0;32m    414\u001b[0m )\n\u001b[1;32m--> 416\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_initiate_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    418\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\CARLES\\anaconda3\\envs\\financialkeepcoders\\lib\\site-packages\\google\\resumable_media\\_upload.py:518\u001b[0m, in \u001b[0;36mResumableUpload._process_initiate_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    503\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Process the response from an HTTP request that initiated upload.\u001b[39;00m\n\u001b[0;32m    504\u001b[0m \n\u001b[0;32m    505\u001b[0m \u001b[38;5;124;03mThis is everything that must be done after a request that doesn't\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    516\u001b[0m \u001b[38;5;124;03m.. _sans-I/O: https://sans-io.readthedocs.io/\u001b[39;00m\n\u001b[0;32m    517\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 518\u001b[0m \u001b[43m_helpers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequire_status_code\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    519\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    520\u001b[0m \u001b[43m    \u001b[49m\u001b[43m(\u001b[49m\u001b[43mhttp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mOK\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhttp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCREATED\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    521\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_status_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    522\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_invalid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    523\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    524\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_resumable_url \u001b[38;5;241m=\u001b[39m _helpers\u001b[38;5;241m.\u001b[39mheader_required(\n\u001b[0;32m    525\u001b[0m     response, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlocation\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_headers\n\u001b[0;32m    526\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\CARLES\\anaconda3\\envs\\financialkeepcoders\\lib\\site-packages\\google\\resumable_media\\_helpers.py:108\u001b[0m, in \u001b[0;36mrequire_status_code\u001b[1;34m(response, status_codes, get_status_code, callback)\u001b[0m\n\u001b[0;32m    107\u001b[0m         callback()\n\u001b[1;32m--> 108\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m common\u001b[38;5;241m.\u001b[39mInvalidResponse(\n\u001b[0;32m    109\u001b[0m         response,\n\u001b[0;32m    110\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRequest failed with status code\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    111\u001b[0m         status_code,\n\u001b[0;32m    112\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected one of\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    113\u001b[0m         \u001b[38;5;241m*\u001b[39mstatus_codes\n\u001b[0;32m    114\u001b[0m     )\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m status_code\n",
      "\u001b[1;31mInvalidResponse\u001b[0m: ('Request failed with status code', 400, 'Expected one of', <HTTPStatus.OK: 200>, <HTTPStatus.CREATED: 201>)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mBadRequest\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\CARLES\\anaconda3\\envs\\financialkeepcoders\\lib\\site-packages\\pandas_gbq\\gbq.py:544\u001b[0m, in \u001b[0;36mGbqConnector.load_data\u001b[1;34m(self, dataframe, destination_table_ref, write_disposition, chunksize, schema, progress_bar, api_method, billing_project)\u001b[0m\n\u001b[0;32m    543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 544\u001b[0m     chunks \u001b[38;5;241m=\u001b[39m \u001b[43mload\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_chunks\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    545\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    546\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdataframe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    547\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdestination_table_ref\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    548\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    549\u001b[0m \u001b[43m        \u001b[49m\u001b[43mschema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    550\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlocation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    551\u001b[0m \u001b[43m        \u001b[49m\u001b[43mapi_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mapi_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    552\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwrite_disposition\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwrite_disposition\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    553\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbilling_project\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbilling_project\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    554\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    555\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m progress_bar \u001b[38;5;129;01mand\u001b[39;00m tqdm:\n",
      "File \u001b[1;32mc:\\Users\\CARLES\\anaconda3\\envs\\financialkeepcoders\\lib\\site-packages\\pandas_gbq\\load.py:251\u001b[0m, in \u001b[0;36mload_chunks\u001b[1;34m(client, dataframe, destination_table_ref, chunksize, schema, location, api_method, write_disposition, billing_project)\u001b[0m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m api_method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mload_parquet\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 251\u001b[0m     \u001b[43mload_parquet\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdataframe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdestination_table_ref\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwrite_disposition\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    256\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    257\u001b[0m \u001b[43m        \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    258\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbilling_project\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbilling_project\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    259\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;66;03m# TODO: yield progress depending on result() with timeout\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\CARLES\\anaconda3\\envs\\financialkeepcoders\\lib\\site-packages\\pandas_gbq\\load.py:139\u001b[0m, in \u001b[0;36mload_parquet\u001b[1;34m(client, dataframe, destination_table_ref, write_disposition, location, schema, billing_project)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 139\u001b[0m     \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_table_from_dataframe\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    140\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdataframe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdestination_table_ref\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    142\u001b[0m \u001b[43m        \u001b[49m\u001b[43mjob_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjob_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    143\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    144\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproject\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbilling_project\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    145\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mresult()\n\u001b[0;32m    146\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m pyarrow\u001b[38;5;241m.\u001b[39mlib\u001b[38;5;241m.\u001b[39mArrowInvalid \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[1;32mc:\\Users\\CARLES\\anaconda3\\envs\\financialkeepcoders\\lib\\site-packages\\google\\cloud\\bigquery\\client.py:2833\u001b[0m, in \u001b[0;36mClient.load_table_from_dataframe\u001b[1;34m(self, dataframe, destination, num_retries, job_id, job_id_prefix, location, project, job_config, parquet_compression, timeout)\u001b[0m\n\u001b[0;32m   2832\u001b[0m         file_size \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mgetsize(tmppath)\n\u001b[1;32m-> 2833\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_table_from_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2834\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtmpfile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2835\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdestination\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2836\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnum_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2837\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrewind\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   2838\u001b[0m \u001b[43m            \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfile_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2839\u001b[0m \u001b[43m            \u001b[49m\u001b[43mjob_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjob_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2840\u001b[0m \u001b[43m            \u001b[49m\u001b[43mjob_id_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjob_id_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2841\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlocation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2842\u001b[0m \u001b[43m            \u001b[49m\u001b[43mproject\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproject\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2843\u001b[0m \u001b[43m            \u001b[49m\u001b[43mjob_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_job_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2844\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2845\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2847\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\CARLES\\anaconda3\\envs\\financialkeepcoders\\lib\\site-packages\\google\\cloud\\bigquery\\client.py:2597\u001b[0m, in \u001b[0;36mClient.load_table_from_file\u001b[1;34m(self, file_obj, destination, rewind, size, num_retries, job_id, job_id_prefix, location, project, job_config, timeout)\u001b[0m\n\u001b[0;32m   2596\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m resumable_media\u001b[38;5;241m.\u001b[39mInvalidResponse \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m-> 2597\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mfrom_http_response(exc\u001b[38;5;241m.\u001b[39mresponse)\n\u001b[0;32m   2599\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m typing\u001b[38;5;241m.\u001b[39mcast(LoadJob, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjob_from_resource(response\u001b[38;5;241m.\u001b[39mjson()))\n",
      "\u001b[1;31mBadRequest\u001b[0m: 400 POST https://bigquery.googleapis.com/upload/bigquery/v2/projects/sara-carles-keepcoding/jobs?uploadType=resumable: Provided Schema does not match Table sara-carles-keepcoding:bronze.bronze_ticker_data. Cannot add fields (field: id)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInvalidSchema\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# En el caso de no tener datos en Bigquery, guardamos todo el df\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m---> 11\u001b[0m     \u001b[43mbigquery\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_dataframe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproject\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mif_exists\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mappend\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\CARLES\\Documents\\financialkeepcoders\\utils\\utils_bigquery.py:75\u001b[0m, in \u001b[0;36mBigQueryUtils.save_dataframe\u001b[1;34m(self, df, project_id, dataset, table, if_exists, schema)\u001b[0m\n\u001b[0;32m     65\u001b[0m     pd\u001b[38;5;241m.\u001b[39mDataFrame\u001b[38;5;241m.\u001b[39mto_gbq(\n\u001b[0;32m     66\u001b[0m         df,\n\u001b[0;32m     67\u001b[0m         destination_table\u001b[38;5;241m=\u001b[39mtable_id,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     72\u001b[0m         chunksize \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10000\u001b[39m\n\u001b[0;32m     73\u001b[0m     )\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m: \n\u001b[1;32m---> 75\u001b[0m         \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_gbq\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     76\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     77\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdestination_table\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtable_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     78\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproject_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproject_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     79\u001b[0m \u001b[43m        \u001b[49m\u001b[43mif_exists\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mif_exists\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     80\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcredentials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     81\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10000\u001b[39;49m\n\u001b[0;32m     82\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\CARLES\\anaconda3\\envs\\financialkeepcoders\\lib\\site-packages\\pandas\\core\\frame.py:2088\u001b[0m, in \u001b[0;36mDataFrame.to_gbq\u001b[1;34m(self, destination_table, project_id, chunksize, reauth, if_exists, auth_local_webserver, table_schema, location, progress_bar, credentials)\u001b[0m\n\u001b[0;32m   2003\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2004\u001b[0m \u001b[38;5;124;03mWrite a DataFrame to a Google BigQuery table.\u001b[39;00m\n\u001b[0;32m   2005\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2084\u001b[0m \u001b[38;5;124;03mread_gbq : Read a DataFrame from Google BigQuery.\u001b[39;00m\n\u001b[0;32m   2085\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2086\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m gbq\n\u001b[1;32m-> 2088\u001b[0m \u001b[43mgbq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_gbq\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2089\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2090\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdestination_table\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2091\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproject_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproject_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2092\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2093\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2094\u001b[0m \u001b[43m    \u001b[49m\u001b[43mif_exists\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mif_exists\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2095\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauth_local_webserver\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth_local_webserver\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2096\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtable_schema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtable_schema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2097\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlocation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2098\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2099\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcredentials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2100\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\CARLES\\anaconda3\\envs\\financialkeepcoders\\lib\\site-packages\\pandas\\io\\gbq.py:215\u001b[0m, in \u001b[0;36mto_gbq\u001b[1;34m(dataframe, destination_table, project_id, chunksize, reauth, if_exists, auth_local_webserver, table_schema, location, progress_bar, credentials)\u001b[0m\n\u001b[0;32m    201\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mto_gbq\u001b[39m(\n\u001b[0;32m    202\u001b[0m     dataframe: DataFrame,\n\u001b[0;32m    203\u001b[0m     destination_table: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    212\u001b[0m     credentials\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    213\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    214\u001b[0m     pandas_gbq \u001b[38;5;241m=\u001b[39m _try_import()\n\u001b[1;32m--> 215\u001b[0m     \u001b[43mpandas_gbq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_gbq\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    216\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdataframe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    217\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdestination_table\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    218\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproject_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproject_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    219\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    220\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    221\u001b[0m \u001b[43m        \u001b[49m\u001b[43mif_exists\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mif_exists\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    222\u001b[0m \u001b[43m        \u001b[49m\u001b[43mauth_local_webserver\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth_local_webserver\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    223\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtable_schema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtable_schema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    224\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    225\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    226\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcredentials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    227\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\CARLES\\anaconda3\\envs\\financialkeepcoders\\lib\\site-packages\\pandas_gbq\\gbq.py:1180\u001b[0m, in \u001b[0;36mto_gbq\u001b[1;34m(dataframe, destination_table, project_id, chunksize, reauth, if_exists, auth_local_webserver, table_schema, location, progress_bar, credentials, api_method, verbose, private_key, auth_redirect_uri, client_id, client_secret)\u001b[0m\n\u001b[0;32m   1175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dataframe\u001b[38;5;241m.\u001b[39mempty:\n\u001b[0;32m   1176\u001b[0m     \u001b[38;5;66;03m# Create the table (if needed), but don't try to run a load job with an\u001b[39;00m\n\u001b[0;32m   1177\u001b[0m     \u001b[38;5;66;03m# empty file. See: https://github.com/pydata/pandas-gbq/issues/237\u001b[39;00m\n\u001b[0;32m   1178\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m-> 1180\u001b[0m \u001b[43mconnector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1181\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataframe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1182\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdestination_table_ref\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1183\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwrite_disposition\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwrite_disposition\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1184\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1185\u001b[0m \u001b[43m    \u001b[49m\u001b[43mschema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtable_schema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1186\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1187\u001b[0m \u001b[43m    \u001b[49m\u001b[43mapi_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mapi_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1188\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbilling_project\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproject_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1189\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\CARLES\\anaconda3\\envs\\financialkeepcoders\\lib\\site-packages\\pandas_gbq\\gbq.py:564\u001b[0m, in \u001b[0;36mGbqConnector.load_data\u001b[1;34m(self, dataframe, destination_table_ref, write_disposition, chunksize, schema, progress_bar, api_method, billing_project)\u001b[0m\n\u001b[0;32m    558\u001b[0m         logger\u001b[38;5;241m.\u001b[39minfo(\n\u001b[0;32m    559\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\r\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m out of \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m rows loaded.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    560\u001b[0m                 total_rows \u001b[38;5;241m-\u001b[39m remaining_rows, total_rows\n\u001b[0;32m    561\u001b[0m             )\n\u001b[0;32m    562\u001b[0m         )\n\u001b[0;32m    563\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhttp_error \u001b[38;5;28;01mas\u001b[39;00m ex:\n\u001b[1;32m--> 564\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess_http_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mex\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\CARLES\\anaconda3\\envs\\financialkeepcoders\\lib\\site-packages\\pandas_gbq\\gbq.py:365\u001b[0m, in \u001b[0;36mGbqConnector.process_http_error\u001b[1;34m(ex)\u001b[0m\n\u001b[0;32m    363\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mschema does not match\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m message:\n\u001b[0;32m    364\u001b[0m     error_message \u001b[38;5;241m=\u001b[39m ex\u001b[38;5;241m.\u001b[39merrors[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m--> 365\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m InvalidSchema(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReason: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00merror_message\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    366\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malready exists: table\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m message:\n\u001b[0;32m    367\u001b[0m     error_message \u001b[38;5;241m=\u001b[39m ex\u001b[38;5;241m.\u001b[39merrors[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[1;31mInvalidSchema\u001b[0m: Reason: Provided Schema does not match Table sara-carles-keepcoding:bronze.bronze_ticker_data. Cannot add fields (field: id)"
     ]
    }
   ],
   "source": [
    "# En el caso de tener un df en Bigquery, lo leemos y guardamos solo los nuevos registros\n",
    "try:\n",
    "    # Filtramos solamente los nuevos registros\n",
    "    df_incremental = select_for_incremental(id='id', table=table_conca, new_df=new_df)\n",
    "\n",
    "    # Guardamos los datos en bigquery\n",
    "    bigquery.save_dataframe(df_incremental, project, dataset, table, if_exists='append', schema=None)\n",
    "\n",
    "# En el caso de no tener datos en Bigquery, guardamos todo el df\n",
    "except:\n",
    "    bigquery.save_dataframe(new_df, project, dataset, table, if_exists='append', schema=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "financialkeepcoders",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
