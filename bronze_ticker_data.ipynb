{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from google.cloud import bigquery\n",
    "from google.oauth2 import service_account\n",
    "from google.cloud import bigquery\n",
    "from google.cloud.exceptions import NotFound\n",
    "import pandas as pd\n",
    "import yahoo_fin.stock_info as si\n",
    "from utils.utils_bigquery import *\n",
    "from datetime import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_path = key_path\n",
    "project = project_id\n",
    "dataset = 'bronze'\n",
    "table = 'bronze_ticker_data'\n",
    "table_conca = f'{project}.{dataset}.{table}'\n",
    "\n",
    "schema = [\n",
    "    {'name': 'Date', 'type': 'DATE'},\n",
    "    {'name': 'Ticker', 'type': 'STRING'},\n",
    "    {'name': 'Adj Close', 'type': 'INTEGER'},\n",
    "    {'name': 'Close', 'type': 'INTEGER'},\n",
    "    {'name': 'High', 'type': 'INTEGER'},\n",
    "    {'name': 'Low', 'type': 'INTEGER'},\n",
    "    {'name': 'Open', 'type': 'INTEGER'},\n",
    "    {'name': 'Volume', 'type': 'INTEGER'},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conectamos con Bigquery\n",
    "bigquery = BigQueryUtils(key_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_tickers = get_unique_tickers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asginamos una fecha inicial a cada ticker.\n",
    "# En caso de no tenerlo ya en Biquery, nos traeremos los datos desde esta fecha\n",
    "unique_tickers_initial_date = initial_date_by_ticker(unique_tickers, initial_date='2015-01-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m----> 2\u001b[0m     max_date_by_ticker \u001b[38;5;241m=\u001b[39m \u001b[43mlast_date_by_ticker_saved\u001b[49m\u001b[43m(\u001b[49m\u001b[43munique_tickers_initial_date\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbigquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtable_conca\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(max_date_by_ticker)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\CARLES\\Documents\\financialkeepcoders\\utils\\utils_bigquery.py:140\u001b[0m, in \u001b[0;36mlast_date_by_ticker_saved\u001b[1;34m(max_date_by_ticker, bigquery, table_conca)\u001b[0m\n\u001b[0;32m    137\u001b[0m \u001b[38;5;66;03m# Retrieve data from BigQuery\u001b[39;00m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m--> 140\u001b[0m current_data \u001b[38;5;241m=\u001b[39m \u001b[43mbigquery\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_query\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\"\"\u001b[39;49m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;124;43m    SELECT\u001b[39;49m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;124;43m        * \u001b[39;49m\n\u001b[0;32m    144\u001b[0m \u001b[38;5;124;43m    FROM \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mtable_conca\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m \u001b[39;49m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;124;43m    \u001b[39;49m\u001b[38;5;124;43m\"\"\"\u001b[39;49m\n\u001b[0;32m    146\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    148\u001b[0m \u001b[38;5;66;03m# Convertir todas las fechas a tz-naive (sin zona horaria)\u001b[39;00m\n\u001b[0;32m    149\u001b[0m current_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m current_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mtz_localize(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\CARLES\\Documents\\financialkeepcoders\\utils\\utils_bigquery.py:35\u001b[0m, in \u001b[0;36mBigQueryUtils.run_query\u001b[1;34m(self, query)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\"\"\"\u001b[39;00m\n\u001b[0;32m     33\u001b[0m query_job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mquery(query)\n\u001b[1;32m---> 35\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mquery_job\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_dataframe\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\CARLES\\anaconda3\\envs\\financialkeepcoders\\lib\\site-packages\\google\\cloud\\bigquery\\job\\query.py:2053\u001b[0m, in \u001b[0;36mQueryJob.to_dataframe\u001b[1;34m(self, bqstorage_client, dtypes, progress_bar_type, create_bqstorage_client, max_results, geography_as_object, bool_dtype, int_dtype, float_dtype, string_dtype, date_dtype, datetime_dtype, time_dtype, timestamp_dtype, range_date_dtype, range_datetime_dtype, range_timestamp_dtype)\u001b[0m\n\u001b[0;32m   1846\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return a pandas DataFrame from a QueryJob\u001b[39;00m\n\u001b[0;32m   1847\u001b[0m \n\u001b[0;32m   1848\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2050\u001b[0m \u001b[38;5;124;03m        :mod:`shapely` library cannot be imported.\u001b[39;00m\n\u001b[0;32m   2051\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2052\u001b[0m query_result \u001b[38;5;241m=\u001b[39m wait_for_query(\u001b[38;5;28mself\u001b[39m, progress_bar_type, max_results\u001b[38;5;241m=\u001b[39mmax_results)\n\u001b[1;32m-> 2053\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mquery_result\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_dataframe\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2054\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbqstorage_client\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbqstorage_client\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2055\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtypes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtypes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2056\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprogress_bar_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2057\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_bqstorage_client\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcreate_bqstorage_client\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2058\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgeography_as_object\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeography_as_object\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2059\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbool_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbool_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2060\u001b[0m \u001b[43m    \u001b[49m\u001b[43mint_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mint_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2061\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfloat_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfloat_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2062\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstring_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstring_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2063\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2064\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdatetime_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdatetime_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2065\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtime_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtime_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2066\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimestamp_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimestamp_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2067\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrange_date_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrange_date_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2068\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrange_datetime_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrange_datetime_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2069\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrange_timestamp_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrange_timestamp_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2070\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\CARLES\\anaconda3\\envs\\financialkeepcoders\\lib\\site-packages\\google\\cloud\\bigquery\\table.py:2379\u001b[0m, in \u001b[0;36mRowIterator.to_dataframe\u001b[1;34m(self, bqstorage_client, dtypes, progress_bar_type, create_bqstorage_client, geography_as_object, bool_dtype, int_dtype, float_dtype, string_dtype, date_dtype, datetime_dtype, time_dtype, timestamp_dtype, range_date_dtype, range_datetime_dtype, range_timestamp_dtype)\u001b[0m\n\u001b[0;32m   2376\u001b[0m     create_bqstorage_client \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   2377\u001b[0m     bqstorage_client \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 2379\u001b[0m record_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_arrow\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2380\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprogress_bar_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2381\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbqstorage_client\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbqstorage_client\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2382\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_bqstorage_client\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcreate_bqstorage_client\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2383\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2385\u001b[0m \u001b[38;5;66;03m# Default date dtype is `db_dtypes.DateDtype()` that could cause out of bounds error,\u001b[39;00m\n\u001b[0;32m   2386\u001b[0m \u001b[38;5;66;03m# when pyarrow converts date values to nanosecond precision. To avoid the error, we\u001b[39;00m\n\u001b[0;32m   2387\u001b[0m \u001b[38;5;66;03m# set the date_as_object parameter to True, if necessary.\u001b[39;00m\n\u001b[0;32m   2388\u001b[0m date_as_object \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\CARLES\\anaconda3\\envs\\financialkeepcoders\\lib\\site-packages\\google\\cloud\\bigquery\\table.py:1946\u001b[0m, in \u001b[0;36mRowIterator.to_arrow\u001b[1;34m(self, progress_bar_type, bqstorage_client, create_bqstorage_client)\u001b[0m\n\u001b[0;32m   1941\u001b[0m progress_bar \u001b[38;5;241m=\u001b[39m get_progress_bar(\n\u001b[0;32m   1942\u001b[0m     progress_bar_type, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDownloading\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtotal_rows, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrows\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1943\u001b[0m )\n\u001b[0;32m   1945\u001b[0m record_batches \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m-> 1946\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m record_batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_arrow_iterable(\n\u001b[0;32m   1947\u001b[0m     bqstorage_client\u001b[38;5;241m=\u001b[39mbqstorage_client\n\u001b[0;32m   1948\u001b[0m ):\n\u001b[0;32m   1949\u001b[0m     record_batches\u001b[38;5;241m.\u001b[39mappend(record_batch)\n\u001b[0;32m   1951\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m progress_bar \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1952\u001b[0m         \u001b[38;5;66;03m# In some cases, the number of total rows is not populated\u001b[39;00m\n\u001b[0;32m   1953\u001b[0m         \u001b[38;5;66;03m# until the first page of rows is fetched. Update the\u001b[39;00m\n\u001b[0;32m   1954\u001b[0m         \u001b[38;5;66;03m# progress bar's total to keep an accurate count.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\CARLES\\anaconda3\\envs\\financialkeepcoders\\lib\\site-packages\\google\\cloud\\bigquery\\table.py:1809\u001b[0m, in \u001b[0;36mRowIterator._to_page_iterable\u001b[1;34m(self, bqstorage_download, tabledata_list_download, bqstorage_client)\u001b[0m\n\u001b[0;32m   1802\u001b[0m     bqstorage_client \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1804\u001b[0m result_pages \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1805\u001b[0m     bqstorage_download()\n\u001b[0;32m   1806\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m bqstorage_client \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1807\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m tabledata_list_download()\n\u001b[0;32m   1808\u001b[0m )\n\u001b[1;32m-> 1809\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m result_pages\n",
      "File \u001b[1;32mc:\\Users\\CARLES\\anaconda3\\envs\\financialkeepcoders\\lib\\site-packages\\google\\cloud\\bigquery\\_pandas_helpers.py:920\u001b[0m, in \u001b[0;36m_download_table_bqstorage\u001b[1;34m(project_id, table, bqstorage_client, preserve_order, selected_fields, page_to_item, max_queue_size)\u001b[0m\n\u001b[0;32m    917\u001b[0m     future\u001b[38;5;241m.\u001b[39mresult()\n\u001b[0;32m    919\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 920\u001b[0m     frame \u001b[38;5;241m=\u001b[39m \u001b[43mworker_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_PROGRESS_INTERVAL\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    921\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m frame\n\u001b[0;32m    922\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m queue\u001b[38;5;241m.\u001b[39mEmpty:  \u001b[38;5;66;03m# pragma: NO COVER\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\CARLES\\anaconda3\\envs\\financialkeepcoders\\lib\\queue.py:179\u001b[0m, in \u001b[0;36mQueue.get\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    177\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m remaining \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m:\n\u001b[0;32m    178\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[1;32m--> 179\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnot_empty\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mremaining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    180\u001b[0m item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get()\n\u001b[0;32m    181\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnot_full\u001b[38;5;241m.\u001b[39mnotify()\n",
      "File \u001b[1;32mc:\\Users\\CARLES\\anaconda3\\envs\\financialkeepcoders\\lib\\threading.py:306\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    304\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    305\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 306\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    307\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    308\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m waiter\u001b[38;5;241m.\u001b[39macquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "try:\n",
    "    max_date_by_ticker = last_date_by_ticker_saved(unique_tickers_initial_date, bigquery, table_conca)\n",
    "    print(max_date_by_ticker)\n",
    "\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    max_date_by_ticker = unique_tickers_initial_date\n",
    "    print(max_date_by_ticker)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos obtenidos para AAPL.\n",
      "Datos obtenidos para AMGN.\n",
      "Datos obtenidos para AMZN.\n",
      "Datos obtenidos para AXP.\n",
      "Datos obtenidos para BA.\n",
      "Datos obtenidos para CAT.\n",
      "Datos obtenidos para CRM.\n",
      "Datos obtenidos para CSCO.\n",
      "Datos obtenidos para CVX.\n",
      "Datos obtenidos para DIS.\n",
      "Datos obtenidos para DOW.\n",
      "Datos obtenidos para GS.\n",
      "Datos obtenidos para HD.\n",
      "Datos obtenidos para HON.\n",
      "Datos obtenidos para IBM.\n",
      "Datos obtenidos para INTC.\n",
      "Datos obtenidos para JNJ.\n",
      "Datos obtenidos para JPM.\n",
      "Datos obtenidos para KO.\n",
      "Datos obtenidos para MCD.\n",
      "Datos obtenidos para MMM.\n",
      "Datos obtenidos para MRK.\n",
      "Datos obtenidos para MSFT.\n",
      "Datos obtenidos para NKE.\n",
      "Datos obtenidos para PG.\n",
      "Datos obtenidos para TRV.\n",
      "Datos obtenidos para UNH.\n",
      "Datos obtenidos para V.\n",
      "Datos obtenidos para VZ.\n",
      "Datos obtenidos para WMT.\n"
     ]
    }
   ],
   "source": [
    "# Hacemos un incremental para traernos los últimos registros\n",
    "df = fetch_historical_data(max_date_by_ticker, start_date_col='date', interval='1d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionamos solo los resultados que aun no existen en Bigquery para no añadir duplicados\n",
    "result = process_and_save_joins(df, max_date_by_ticker, bigquery, project, dataset, table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'result' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Guardamos los datos en bigquery\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m bigquery\u001b[38;5;241m.\u001b[39msave_dataframe(\u001b[43mresult\u001b[49m, project, dataset, table, if_exists\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mappend\u001b[39m\u001b[38;5;124m'\u001b[39m, schema\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'result' is not defined"
     ]
    }
   ],
   "source": [
    "# Guardamos los datos en bigquery\n",
    "bigquery.save_dataframe(result, project, dataset, table, if_exists='append')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "financialkeepcoders",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
