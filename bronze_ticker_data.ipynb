{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from google.cloud import bigquery\n",
    "from google.oauth2 import service_account\n",
    "from google.cloud import bigquery\n",
    "from google.cloud.exceptions import NotFound\n",
    "import pandas as pd\n",
    "import yahoo_fin.stock_info as si\n",
    "from utils.utils_bigquery import *\n",
    "from datetime import *\n",
    "import hashlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_path = key_path\n",
    "project = project_id\n",
    "dataset = 'bronze'\n",
    "table = 'bronze_ticker_data'\n",
    "table_conca = f'{project}.{dataset}.{table}'\n",
    "\n",
    "# schema = [\n",
    "#     {'name': 'dd', 'type': 'STRING'},\n",
    "#     {'name': 'date', 'type': 'DATE'},\n",
    "#     {'name': 'ticker', 'type': 'STRING'},\n",
    "#     {'name': 'adj close', 'type': 'INTEGER'},\n",
    "#     {'name': 'close', 'type': 'INTEGER'},\n",
    "#     {'name': 'high', 'type': 'INTEGER'},\n",
    "#     {'name': 'low', 'type': 'INTEGER'},\n",
    "#     {'name': 'Open', 'type': 'INTEGER'},\n",
    "#     {'name': 'Volume', 'type': 'INTEGER'},\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conectamos con Bigquery\n",
    "bigquery = BigQueryUtils(key_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NYMTI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SIX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SBOW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HIBB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CUBA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5962</th>\n",
       "      <td>VTRS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5963</th>\n",
       "      <td>ZTS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5964</th>\n",
       "      <td>CTLT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5965</th>\n",
       "      <td>EBS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5966</th>\n",
       "      <td>PBH</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5967 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     ticker\n",
       "0     NYMTI\n",
       "1       SIX\n",
       "2      SBOW\n",
       "3      HIBB\n",
       "4      CUBA\n",
       "...     ...\n",
       "5962   VTRS\n",
       "5963    ZTS\n",
       "5964   CTLT\n",
       "5965    EBS\n",
       "5966    PBH\n",
       "\n",
       "[5967 rows x 1 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_tickers = bigquery.run_query(\n",
    "    f\"\"\"\n",
    "    SELECT\n",
    "        ticker\n",
    "    FROM sara-carles-keepcoding.bronze.bronze_ticker_info\n",
    "    \"\"\"\n",
    ")\n",
    "unique_tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign an initial date to each ticker.\n",
    "unique_tickers_initial_date = initial_date_by_ticker(unique_tickers, initial_date='2015-01-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "404 Not found: Table sara-carles-keepcoding:bronze.bronze_ticker_data was not found in location EU; reason: notFound, message: Not found: Table sara-carles-keepcoding:bronze.bronze_ticker_data was not found in location EU\n",
      "\n",
      "Location: EU\n",
      "Job ID: 21ce6e64-81b8-4e94-a2ab-bfb210b0531b\n",
      "\n",
      "    ticker initial_date\n",
      "0      COP   2015-01-01\n",
      "1      EOG   2015-01-01\n",
      "2      OXY   2015-01-01\n",
      "3      HES   2015-01-01\n",
      "4     FANG   2015-01-01\n",
      "..     ...          ...\n",
      "498   TTWO   2015-01-01\n",
      "499  GOOGL   2015-01-01\n",
      "500   GOOG   2015-01-01\n",
      "501   META   2015-01-01\n",
      "502   MTCH   2015-01-01\n",
      "\n",
      "[503 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Attempt to fetch the maximum date per ticker from BigQuery; fallback to initial dates if an error occurs.\n",
    "try:\n",
    "    max_date_by_ticker = bigquery.run_query(\n",
    "        f\"\"\"\n",
    "        SELECT\n",
    "            ticker,\n",
    "            max(date) as date \n",
    "        FROM {table_conca} \n",
    "        GROUP BY \n",
    "            ticker\n",
    "        \"\"\"\n",
    "    )\n",
    "    max_date_by_ticker['date'] = pd.to_datetime(max_date_by_ticker['date'])\n",
    "    max_date_by_ticker['date'] = max_date_by_ticker['date'].dt.tz_localize(None)\n",
    "    \n",
    "    # Merge with the DataFrame of unique tickers\n",
    "    max_date_by_ticker = pd.merge(unique_tickers_initial_date, max_date_by_ticker, how='left', on='ticker')\n",
    "\n",
    "    # Keep the maximum date between both fields\n",
    "    max_date_by_ticker['date'] = max_date_by_ticker[['date', 'initial_date']].max(axis=1)\n",
    "\n",
    "    # Remove the auxiliary 'initial_date' column\n",
    "    max_date_by_ticker.drop(columns=['initial_date'], inplace=True)\n",
    "\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    max_date_by_ticker = unique_tickers_initial_date\n",
    "    print(max_date_by_ticker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos obtenidos para COP.\n",
      "Datos obtenidos para EOG.\n",
      "Datos obtenidos para OXY.\n",
      "Datos obtenidos para HES.\n",
      "Datos obtenidos para FANG.\n",
      "Datos obtenidos para DVN.\n",
      "Datos obtenidos para EQT.\n",
      "Datos obtenidos para CTRA.\n",
      "Datos obtenidos para MRO.\n",
      "Datos obtenidos para APA.\n",
      "Datos obtenidos para WMB.\n",
      "Datos obtenidos para OKE.\n",
      "Datos obtenidos para KMI.\n",
      "Datos obtenidos para TRGP.\n",
      "Datos obtenidos para XOM.\n",
      "Datos obtenidos para CVX.\n",
      "Datos obtenidos para SLB.\n",
      "Datos obtenidos para BKR.\n",
      "Datos obtenidos para HAL.\n",
      "Datos obtenidos para MPC.\n",
      "Datos obtenidos para PSX.\n",
      "Datos obtenidos para VLO.\n",
      "Datos obtenidos para CEG.\n",
      "Datos obtenidos para GEV.\n",
      "Datos obtenidos para SRE.\n",
      "Datos obtenidos para AES.\n",
      "Datos obtenidos para ATO.\n",
      "Datos obtenidos para NI.\n",
      "Datos obtenidos para AWK.\n",
      "Datos obtenidos para NEE.\n",
      "Datos obtenidos para SO.\n",
      "Datos obtenidos para DUK.\n",
      "Datos obtenidos para AEP.\n",
      "Datos obtenidos para PCG.\n",
      "Datos obtenidos para D.\n",
      "Datos obtenidos para PEG.\n",
      "Datos obtenidos para EXC.\n",
      "Datos obtenidos para ED.\n",
      "Datos obtenidos para XEL.\n",
      "Datos obtenidos para EIX.\n",
      "Datos obtenidos para WEC.\n",
      "Datos obtenidos para DTE.\n",
      "Datos obtenidos para ETR.\n",
      "Datos obtenidos para FE.\n",
      "Datos obtenidos para ES.\n",
      "Datos obtenidos para PPL.\n",
      "Datos obtenidos para AEE.\n",
      "Datos obtenidos para CMS.\n",
      "Datos obtenidos para CNP.\n",
      "Datos obtenidos para LNT.\n",
      "Datos obtenidos para EVRG.\n",
      "Datos obtenidos para PNW.\n",
      "Datos obtenidos para VST.\n",
      "Datos obtenidos para NRG.\n",
      "Datos obtenidos para REGN.\n",
      "Datos obtenidos para VRTX.\n",
      "Datos obtenidos para MRNA.\n",
      "Datos obtenidos para INCY.\n",
      "Datos obtenidos para TECH.\n",
      "Datos obtenidos para ABT.\n",
      "Datos obtenidos para SYK.\n",
      "Datos obtenidos para BSX.\n",
      "Datos obtenidos para MDT.\n",
      "Datos obtenidos para EW.\n",
      "Datos obtenidos para DXCM.\n",
      "Datos obtenidos para STE.\n",
      "Datos obtenidos para ZBH.\n",
      "Datos obtenidos para PODD.\n",
      "Datos obtenidos para BIO.\n",
      "Datos obtenidos para UNH.\n",
      "Datos obtenidos para ELV.\n",
      "Datos obtenidos para CI.\n",
      "Datos obtenidos para CVS.\n",
      "Datos obtenidos para HUM.\n",
      "Datos obtenidos para CNC.\n",
      "Datos obtenidos para MOH.\n",
      "Datos obtenidos para MCK.\n",
      "Datos obtenidos para COR.\n",
      "Datos obtenidos para CAH.\n",
      "Datos obtenidos para HSIC.\n",
      "Datos obtenidos para TMO.\n",
      "Datos obtenidos para DHR.\n",
      "Datos obtenidos para IQV.\n",
      "Datos obtenidos para A.\n",
      "Datos obtenidos para IDXX.\n",
      "Datos obtenidos para MTD.\n",
      "Datos obtenidos para WAT.\n",
      "Datos obtenidos para LH.\n",
      "Datos obtenidos para DGX.\n",
      "Datos obtenidos para RVTY.\n",
      "Datos obtenidos para CRL.\n",
      "Datos obtenidos para HCA.\n",
      "Datos obtenidos para UHS.\n",
      "Datos obtenidos para DVA.\n",
      "Datos obtenidos para WBA.\n",
      "Datos obtenidos para GEHC.\n",
      "Datos obtenidos para SOLV.\n",
      "Datos obtenidos para LLY.\n",
      "Datos obtenidos para JNJ.\n",
      "Datos obtenidos para ABBV.\n",
      "Datos obtenidos para MRK.\n",
      "Datos obtenidos para AMGN.\n",
      "Datos obtenidos para PFE.\n",
      "Datos obtenidos para BMY.\n",
      "Datos obtenidos para GILD.\n",
      "Datos obtenidos para BIIB.\n",
      "Datos obtenidos para ISRG.\n",
      "Datos obtenidos para BDX.\n",
      "Datos obtenidos para RMD.\n",
      "Datos obtenidos para WST.\n",
      "Datos obtenidos para COO.\n",
      "Datos obtenidos para HOLX.\n",
      "Datos obtenidos para BAX.\n",
      "Datos obtenidos para ALGN.\n",
      "Datos obtenidos para TFX.\n",
      "Datos obtenidos para ZTS.\n",
      "Datos obtenidos para VTRS.\n",
      "Datos obtenidos para CTLT.\n",
      "Datos obtenidos para FSLR.\n",
      "Datos obtenidos para ENPH.\n",
      "Datos obtenidos para NVDA.\n",
      "Datos obtenidos para AVGO.\n",
      "Datos obtenidos para AMD.\n",
      "Datos obtenidos para QCOM.\n",
      "Datos obtenidos para TXN.\n",
      "Datos obtenidos para MU.\n",
      "Datos obtenidos para ADI.\n",
      "Datos obtenidos para INTC.\n",
      "Datos obtenidos para NXPI.\n",
      "Datos obtenidos para MPWR.\n",
      "Datos obtenidos para MCHP.\n",
      "Datos obtenidos para ON.\n",
      "Datos obtenidos para SWKS.\n",
      "Datos obtenidos para QRVO.\n",
      "Datos obtenidos para ANET.\n",
      "Datos obtenidos para SMCI.\n",
      "Datos obtenidos para HPQ.\n",
      "Datos obtenidos para NTAP.\n",
      "Datos obtenidos para STX.\n",
      "Datos obtenidos para WDC.\n",
      "Datos obtenidos para AAPL.\n",
      "Datos obtenidos para APH.\n",
      "Datos obtenidos para TEL.\n",
      "Datos obtenidos para GLW.\n",
      "Datos obtenidos para JBL.\n",
      "Datos obtenidos para CRM.\n",
      "Datos obtenidos para INTU.\n",
      "Datos obtenidos para NOW.\n",
      "Datos obtenidos para UBER.\n",
      "Datos obtenidos para ADP.\n",
      "Datos obtenidos para CDNS.\n",
      "Datos obtenidos para ROP.\n",
      "Datos obtenidos para ADSK.\n",
      "Datos obtenidos para PAYX.\n",
      "Datos obtenidos para FICO.\n",
      "Datos obtenidos para ANSS.\n",
      "Datos obtenidos para TYL.\n",
      "Datos obtenidos para PTC.\n",
      "Datos obtenidos para PAYC.\n",
      "Datos obtenidos para DAY.\n",
      "Datos obtenidos para CSCO.\n",
      "Datos obtenidos para MSI.\n",
      "Datos obtenidos para HPE.\n",
      "Datos obtenidos para ZBRA.\n",
      "Datos obtenidos para JNPR.\n",
      "Datos obtenidos para MSFT.\n",
      "Datos obtenidos para ORCL.\n",
      "Datos obtenidos para ADBE.\n",
      "Datos obtenidos para PANW.\n",
      "Datos obtenidos para SNPS.\n",
      "Datos obtenidos para CRWD.\n",
      "Datos obtenidos para FTNT.\n",
      "Datos obtenidos para GDDY.\n",
      "Datos obtenidos para CPAY.\n",
      "Datos obtenidos para VRSN.\n",
      "Datos obtenidos para GEN.\n",
      "Datos obtenidos para AKAM.\n",
      "Datos obtenidos para FFIV.\n",
      "Datos obtenidos para ACN.\n",
      "Datos obtenidos para IBM.\n",
      "Datos obtenidos para FI.\n",
      "Datos obtenidos para FIS.\n",
      "Datos obtenidos para CTSH.\n",
      "Datos obtenidos para IT.\n",
      "Datos obtenidos para CDW.\n",
      "Datos obtenidos para BR.\n",
      "Datos obtenidos para LDOS.\n",
      "Datos obtenidos para JKHY.\n",
      "Datos obtenidos para EPAM.\n",
      "Datos obtenidos para GRMN.\n",
      "Datos obtenidos para FTV.\n",
      "Datos obtenidos para KEYS.\n",
      "Datos obtenidos para TDY.\n",
      "Datos obtenidos para TRMB.\n",
      "Datos obtenidos para AMAT.\n",
      "Datos obtenidos para LRCX.\n",
      "Datos obtenidos para KLAC.\n",
      "Datos obtenidos para TER.\n",
      "Datos obtenidos para DAL.\n",
      "Datos obtenidos para LUV.\n",
      "Datos obtenidos para UAL.\n",
      "Datos obtenidos para AAL.\n",
      "Datos obtenidos para ODFL.\n",
      "Datos obtenidos para UNP.\n",
      "Datos obtenidos para CSX.\n",
      "Datos obtenidos para NSC.\n",
      "Datos obtenidos para WAB.\n",
      "Datos obtenidos para HON.\n",
      "Datos obtenidos para MMM.\n",
      "Datos obtenidos para WM.\n",
      "Datos obtenidos para RSG.\n",
      "Datos obtenidos para GE.\n",
      "Datos obtenidos para RTX.\n",
      "Datos obtenidos para LMT.\n",
      "Datos obtenidos para BA.\n",
      "Datos obtenidos para GD.\n",
      "Datos obtenidos para NOC.\n",
      "Datos obtenidos para TDG.\n",
      "Datos obtenidos para LHX.\n",
      "Datos obtenidos para HWM.\n",
      "Datos obtenidos para AXON.\n",
      "Datos obtenidos para TXT.\n",
      "Datos obtenidos para HII.\n",
      "Datos obtenidos para VRSK.\n",
      "Datos obtenidos para EFX.\n",
      "Datos obtenidos para SWK.\n",
      "Datos obtenidos para SNA.\n",
      "Datos obtenidos para GWW.\n",
      "Datos obtenidos para FAST.\n",
      "Datos obtenidos para POOL.\n",
      "Datos obtenidos para URI.\n",
      "Datos obtenidos para PWR.\n",
      "Datos obtenidos para J.\n",
      "Datos obtenidos para CTAS.\n",
      "Datos obtenidos para CPRT.\n",
      "Datos obtenidos para GPN.\n",
      "Datos obtenidos para HUBB.\n",
      "Datos obtenidos para TT.\n",
      "Datos obtenidos para CARR.\n",
      "Datos obtenidos para JCI.\n",
      "Datos obtenidos para BLDR.\n",
      "Datos obtenidos para MAS.\n",
      "Datos obtenidos para UPS.\n",
      "Datos obtenidos para FDX.\n",
      "Datos obtenidos para JBHT.\n",
      "Datos obtenidos para EXPD.\n",
      "Datos obtenidos para CHRW.\n",
      "Datos obtenidos para VLTO.\n",
      "Datos obtenidos para ALLE.\n",
      "Datos obtenidos para ETN.\n",
      "Datos obtenidos para PH.\n",
      "Datos obtenidos para ITW.\n",
      "Datos obtenidos para EMR.\n",
      "Datos obtenidos para CMI.\n",
      "Datos obtenidos para AME.\n",
      "Datos obtenidos para OTIS.\n",
      "Datos obtenidos para IR.\n",
      "Datos obtenidos para XYL.\n",
      "Datos obtenidos para ROK.\n",
      "Datos obtenidos para DOV.\n",
      "Datos obtenidos para IEX.\n",
      "Datos obtenidos para PNR.\n",
      "Datos obtenidos para NDSN.\n",
      "Datos obtenidos para AOS.\n",
      "Datos obtenidos para GNRC.\n",
      "Datos obtenidos para CAT.\n",
      "Datos obtenidos para DE.\n",
      "Datos obtenidos para PCAR.\n",
      "Datos obtenidos para ARE.\n",
      "Datos obtenidos para BXP.\n",
      "Datos obtenidos para SPG.\n",
      "Datos obtenidos para O.\n",
      "Datos obtenidos para KIM.\n",
      "Datos obtenidos para REG.\n",
      "Datos obtenidos para FRT.\n",
      "Datos obtenidos para AMT.\n",
      "Datos obtenidos para EQIX.\n",
      "Datos obtenidos para DLR.\n",
      "Datos obtenidos para CCI.\n",
      "Datos obtenidos para IRM.\n",
      "Datos obtenidos para SBAC.\n",
      "Datos obtenidos para WY.\n",
      "Datos obtenidos para PLD.\n",
      "Datos obtenidos para PSA.\n",
      "Datos obtenidos para EXR.\n",
      "Datos obtenidos para VICI.\n",
      "Datos obtenidos para AVB.\n",
      "Datos obtenidos para EQR.\n",
      "Datos obtenidos para INVH.\n",
      "Datos obtenidos para ESS.\n",
      "Datos obtenidos para MAA.\n",
      "Datos obtenidos para UDR.\n",
      "Datos obtenidos para CPT.\n",
      "Datos obtenidos para HST.\n",
      "Datos obtenidos para CBRE.\n",
      "Datos obtenidos para CSGP.\n",
      "Datos obtenidos para WELL.\n",
      "Datos obtenidos para VTR.\n",
      "Datos obtenidos para DOC.\n",
      "Datos obtenidos para NEM.\n",
      "Datos obtenidos para NUE.\n",
      "Datos obtenidos para STLD.\n",
      "Datos obtenidos para FCX.\n",
      "Datos obtenidos para DOW.\n",
      "Datos obtenidos para CE.\n",
      "Datos obtenidos para MLM.\n",
      "Datos obtenidos para VMC.\n",
      "Datos obtenidos para CTVA.\n",
      "Datos obtenidos para CF.\n",
      "Datos obtenidos para MOS.\n",
      "Datos obtenidos para FMC.\n",
      "Datos obtenidos para LIN.\n",
      "Datos obtenidos para SHW.\n",
      "Datos obtenidos para ECL.\n",
      "Datos obtenidos para APD.\n",
      "Datos obtenidos para DD.\n",
      "Datos obtenidos para LYB.\n",
      "Datos obtenidos para PPG.\n",
      "Datos obtenidos para IFF.\n",
      "Datos obtenidos para EMN.\n",
      "Datos obtenidos para ALB.\n",
      "Datos obtenidos para HAS.\n",
      "Datos obtenidos para MAR.\n",
      "Datos obtenidos para HLT.\n",
      "Datos obtenidos para GPC.\n",
      "Datos obtenidos para APTV.\n",
      "Datos obtenidos para LKQ.\n",
      "Datos obtenidos para BWA.\n",
      "Datos obtenidos para MCD.\n",
      "Datos obtenidos para SBUX.\n",
      "Datos obtenidos para CMG.\n",
      "Datos obtenidos para YUM.\n",
      "Datos obtenidos para DRI.\n",
      "Datos obtenidos para DPZ.\n",
      "Datos obtenidos para TPR.\n",
      "Datos obtenidos para TJX.\n",
      "Datos obtenidos para ROST.\n",
      "Datos obtenidos para LULU.\n",
      "Datos obtenidos para AMZN.\n",
      "Datos obtenidos para EBAY.\n",
      "Datos obtenidos para ETSY.\n",
      "Datos obtenidos para BKNG.\n",
      "Datos obtenidos para ABNB.\n",
      "Datos obtenidos para RCL.\n",
      "Datos obtenidos para CCL.\n",
      "Datos obtenidos para EXPE.\n",
      "Datos obtenidos para NCLH.\n",
      "Datos obtenidos para ORLY.\n",
      "Datos obtenidos para AZO.\n",
      "Datos obtenidos para TSCO.\n",
      "Datos obtenidos para BBY.\n",
      "Datos obtenidos para ULTA.\n",
      "Datos obtenidos para BBWI.\n",
      "Datos obtenidos para ROL.\n",
      "Datos obtenidos para LVS.\n",
      "Datos obtenidos para MGM.\n",
      "Datos obtenidos para WYNN.\n",
      "Datos obtenidos para CZR.\n",
      "Datos obtenidos para TSLA.\n",
      "Datos obtenidos para GM.\n",
      "Datos obtenidos para F.\n",
      "Datos obtenidos para RL.\n",
      "Datos obtenidos para NKE.\n",
      "Datos obtenidos para DECK.\n",
      "Datos obtenidos para SW.\n",
      "Datos obtenidos para BALL.\n",
      "Datos obtenidos para PKG.\n",
      "Datos obtenidos para AVY.\n",
      "Datos obtenidos para IP.\n",
      "Datos obtenidos para AMCR.\n",
      "Datos obtenidos para HD.\n",
      "Datos obtenidos para LOW.\n",
      "Datos obtenidos para KMX.\n",
      "Datos obtenidos para DHI.\n",
      "Datos obtenidos para LEN.\n",
      "Datos obtenidos para NVR.\n",
      "Datos obtenidos para PHM.\n",
      "Datos obtenidos para MHK.\n",
      "Datos obtenidos para PM.\n",
      "Datos obtenidos para MO.\n",
      "Datos obtenidos para MDLZ.\n",
      "Datos obtenidos para HSY.\n",
      "Datos obtenidos para ADM.\n",
      "Datos obtenidos para TSN.\n",
      "Datos obtenidos para BG.\n",
      "Datos obtenidos para KR.\n",
      "Datos obtenidos para KHC.\n",
      "Datos obtenidos para GIS.\n",
      "Datos obtenidos para K.\n",
      "Datos obtenidos para MKC.\n",
      "Datos obtenidos para HRL.\n",
      "Datos obtenidos para CPB.\n",
      "Datos obtenidos para CAG.\n",
      "Datos obtenidos para SJM.\n",
      "Datos obtenidos para LW.\n",
      "Datos obtenidos para WMT.\n",
      "Datos obtenidos para COST.\n",
      "Datos obtenidos para TGT.\n",
      "Datos obtenidos para DG.\n",
      "Datos obtenidos para DLTR.\n",
      "Datos obtenidos para SYY.\n",
      "Datos obtenidos para STZ.\n",
      "Datos obtenidos para TAP.\n",
      "Datos obtenidos para KO.\n",
      "Datos obtenidos para PEP.\n",
      "Datos obtenidos para KDP.\n",
      "Datos obtenidos para MNST.\n",
      "Datos obtenidos para PG.\n",
      "Datos obtenidos para CL.\n",
      "Datos obtenidos para KMB.\n",
      "Datos obtenidos para KVUE.\n",
      "Datos obtenidos para EL.\n",
      "Datos obtenidos para CHD.\n",
      "Datos obtenidos para CLX.\n",
      "Datos obtenidos para BF-B.\n",
      "Datos obtenidos para MS.\n",
      "Datos obtenidos para GS.\n",
      "Datos obtenidos para SCHW.\n",
      "Datos obtenidos para MKTX.\n",
      "Datos obtenidos para V.\n",
      "Datos obtenidos para MA.\n",
      "Datos obtenidos para AXP.\n",
      "Datos obtenidos para PYPL.\n",
      "Datos obtenidos para COF.\n",
      "Datos obtenidos para DFS.\n",
      "Datos obtenidos para SYF.\n",
      "Datos obtenidos para BX.\n",
      "Datos obtenidos para BLK.\n",
      "Datos obtenidos para KKR.\n",
      "Datos obtenidos para BK.\n",
      "Datos obtenidos para AMP.\n",
      "Datos obtenidos para TROW.\n",
      "Datos obtenidos para STT.\n",
      "Datos obtenidos para RJF.\n",
      "Datos obtenidos para PFG.\n",
      "Datos obtenidos para NTRS.\n",
      "Datos obtenidos para BEN.\n",
      "Datos obtenidos para IVZ.\n",
      "Datos obtenidos para PNC.\n",
      "Datos obtenidos para USB.\n",
      "Datos obtenidos para TFC.\n",
      "Datos obtenidos para FITB.\n",
      "Datos obtenidos para MTB.\n",
      "Datos obtenidos para HBAN.\n",
      "Datos obtenidos para RF.\n",
      "Datos obtenidos para CFG.\n",
      "Datos obtenidos para KEY.\n",
      "Datos obtenidos para AFL.\n",
      "Datos obtenidos para MET.\n",
      "Datos obtenidos para PRU.\n",
      "Datos obtenidos para GL.\n",
      "Datos obtenidos para MMC.\n",
      "Datos obtenidos para AON.\n",
      "Datos obtenidos para AJG.\n",
      "Datos obtenidos para BRO.\n",
      "Datos obtenidos para WTW.\n",
      "Datos obtenidos para JPM.\n",
      "Datos obtenidos para BAC.\n",
      "Datos obtenidos para WFC.\n",
      "Datos obtenidos para C.\n",
      "Datos obtenidos para AIZ.\n",
      "Datos obtenidos para BRK-B.\n",
      "Datos obtenidos para AIG.\n",
      "Datos obtenidos para ACGL.\n",
      "Datos obtenidos para EG.\n",
      "Datos obtenidos para PGR.\n",
      "Datos obtenidos para CB.\n",
      "Datos obtenidos para TRV.\n",
      "Datos obtenidos para ALL.\n",
      "Datos obtenidos para HIG.\n",
      "Datos obtenidos para WRB.\n",
      "Datos obtenidos para CINF.\n",
      "Datos obtenidos para L.\n",
      "Datos obtenidos para SPGI.\n",
      "Datos obtenidos para ICE.\n",
      "Datos obtenidos para MCO.\n",
      "Datos obtenidos para CME.\n",
      "Datos obtenidos para MSCI.\n",
      "Datos obtenidos para NDAQ.\n",
      "Datos obtenidos para CBOE.\n",
      "Datos obtenidos para FDS.\n",
      "Datos obtenidos para NFLX.\n",
      "Datos obtenidos para DIS.\n",
      "Datos obtenidos para LYV.\n",
      "Datos obtenidos para WBD.\n",
      "Datos obtenidos para FOXA.\n",
      "Datos obtenidos para FOX.\n",
      "Datos obtenidos para NWS.\n",
      "Datos obtenidos para NWSA.\n",
      "Datos obtenidos para PARA.\n",
      "Datos obtenidos para TMUS.\n",
      "Datos obtenidos para VZ.\n",
      "Datos obtenidos para CMCSA.\n",
      "Datos obtenidos para T.\n",
      "Datos obtenidos para CHTR.\n",
      "Datos obtenidos para OMC.\n",
      "Datos obtenidos para IPG.\n",
      "Datos obtenidos para EA.\n",
      "Datos obtenidos para TTWO.\n",
      "Datos obtenidos para GOOGL.\n",
      "Datos obtenidos para GOOG.\n",
      "Datos obtenidos para META.\n",
      "Datos obtenidos para MTCH.\n"
     ]
    }
   ],
   "source": [
    "# Perform an incremental update to fetch the latest records\n",
    "try:\n",
    "    new_df = fetch_historical_data(max_date_by_ticker, start_date_col='date', interval='1d')\n",
    "    new_df\n",
    "except:\n",
    "    new_df = fetch_historical_data(max_date_by_ticker, start_date_col='initial_date', interval='1d')\n",
    "    new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>adjclose</th>\n",
       "      <th>volume</th>\n",
       "      <th>ticker</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>68.500000</td>\n",
       "      <td>69.480003</td>\n",
       "      <td>68.230003</td>\n",
       "      <td>68.919998</td>\n",
       "      <td>55.644146</td>\n",
       "      <td>5701800</td>\n",
       "      <td>COP</td>\n",
       "      <td>4342948b0ecbd3d9b2bd691bb3d0f45a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>67.709999</td>\n",
       "      <td>67.980003</td>\n",
       "      <td>65.430000</td>\n",
       "      <td>65.639999</td>\n",
       "      <td>52.995972</td>\n",
       "      <td>10938900</td>\n",
       "      <td>COP</td>\n",
       "      <td>8035c040b4c16aaae94334be92d773fd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-06</td>\n",
       "      <td>65.290001</td>\n",
       "      <td>66.599998</td>\n",
       "      <td>62.880001</td>\n",
       "      <td>62.930000</td>\n",
       "      <td>50.807991</td>\n",
       "      <td>18054700</td>\n",
       "      <td>COP</td>\n",
       "      <td>273e2f6115430f61fc8d6cfe366d260e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-07</td>\n",
       "      <td>64.010002</td>\n",
       "      <td>64.230003</td>\n",
       "      <td>62.849998</td>\n",
       "      <td>63.349998</td>\n",
       "      <td>51.147091</td>\n",
       "      <td>12350500</td>\n",
       "      <td>COP</td>\n",
       "      <td>4581c3e5a836782fddb2a4505e45fb66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-08</td>\n",
       "      <td>64.849998</td>\n",
       "      <td>65.489998</td>\n",
       "      <td>63.900002</td>\n",
       "      <td>64.930000</td>\n",
       "      <td>52.422737</td>\n",
       "      <td>10348300</td>\n",
       "      <td>COP</td>\n",
       "      <td>2475f7a4282d8fdbe55aefd82b119046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1189023</th>\n",
       "      <td>2024-08-19</td>\n",
       "      <td>34.910000</td>\n",
       "      <td>36.700001</td>\n",
       "      <td>34.910000</td>\n",
       "      <td>36.580002</td>\n",
       "      <td>36.580002</td>\n",
       "      <td>3884700</td>\n",
       "      <td>MTCH</td>\n",
       "      <td>cd0484f31059c8724b858370c1dc9b8f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1189024</th>\n",
       "      <td>2024-08-20</td>\n",
       "      <td>36.360001</td>\n",
       "      <td>36.595001</td>\n",
       "      <td>36.169998</td>\n",
       "      <td>36.529999</td>\n",
       "      <td>36.529999</td>\n",
       "      <td>3375900</td>\n",
       "      <td>MTCH</td>\n",
       "      <td>d7b903d7ef9849e21d50e60813dbfebd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1189025</th>\n",
       "      <td>2024-08-21</td>\n",
       "      <td>36.689999</td>\n",
       "      <td>37.580002</td>\n",
       "      <td>36.439999</td>\n",
       "      <td>37.139999</td>\n",
       "      <td>37.139999</td>\n",
       "      <td>4550400</td>\n",
       "      <td>MTCH</td>\n",
       "      <td>c2e2f3489b2be3381ced46016e4ed21d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1189026</th>\n",
       "      <td>2024-08-22</td>\n",
       "      <td>37.099998</td>\n",
       "      <td>37.160000</td>\n",
       "      <td>36.360001</td>\n",
       "      <td>36.419998</td>\n",
       "      <td>36.419998</td>\n",
       "      <td>4800500</td>\n",
       "      <td>MTCH</td>\n",
       "      <td>7ff4851947e5aec2c4f32365c70f10a3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1189027</th>\n",
       "      <td>2024-08-23</td>\n",
       "      <td>36.669998</td>\n",
       "      <td>37.424999</td>\n",
       "      <td>36.590000</td>\n",
       "      <td>37.320000</td>\n",
       "      <td>37.320000</td>\n",
       "      <td>5294400</td>\n",
       "      <td>MTCH</td>\n",
       "      <td>faf5ba60eccd06b480f997a4023d62a0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1189028 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              date       open       high        low      close   adjclose  \\\n",
       "0       2015-01-02  68.500000  69.480003  68.230003  68.919998  55.644146   \n",
       "1       2015-01-05  67.709999  67.980003  65.430000  65.639999  52.995972   \n",
       "2       2015-01-06  65.290001  66.599998  62.880001  62.930000  50.807991   \n",
       "3       2015-01-07  64.010002  64.230003  62.849998  63.349998  51.147091   \n",
       "4       2015-01-08  64.849998  65.489998  63.900002  64.930000  52.422737   \n",
       "...            ...        ...        ...        ...        ...        ...   \n",
       "1189023 2024-08-19  34.910000  36.700001  34.910000  36.580002  36.580002   \n",
       "1189024 2024-08-20  36.360001  36.595001  36.169998  36.529999  36.529999   \n",
       "1189025 2024-08-21  36.689999  37.580002  36.439999  37.139999  37.139999   \n",
       "1189026 2024-08-22  37.099998  37.160000  36.360001  36.419998  36.419998   \n",
       "1189027 2024-08-23  36.669998  37.424999  36.590000  37.320000  37.320000   \n",
       "\n",
       "           volume ticker                                id  \n",
       "0         5701800    COP  4342948b0ecbd3d9b2bd691bb3d0f45a  \n",
       "1        10938900    COP  8035c040b4c16aaae94334be92d773fd  \n",
       "2        18054700    COP  273e2f6115430f61fc8d6cfe366d260e  \n",
       "3        12350500    COP  4581c3e5a836782fddb2a4505e45fb66  \n",
       "4        10348300    COP  2475f7a4282d8fdbe55aefd82b119046  \n",
       "...           ...    ...                               ...  \n",
       "1189023   3884700   MTCH  cd0484f31059c8724b858370c1dc9b8f  \n",
       "1189024   3375900   MTCH  d7b903d7ef9849e21d50e60813dbfebd  \n",
       "1189025   4550400   MTCH  c2e2f3489b2be3381ced46016e4ed21d  \n",
       "1189026   4800500   MTCH  7ff4851947e5aec2c4f32365c70f10a3  \n",
       "1189027   5294400   MTCH  faf5ba60eccd06b480f997a4023d62a0  \n",
       "\n",
       "[1189028 rows x 9 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fields that make up the ID\n",
    "id_fields = ['ticker', 'date']\n",
    "\n",
    "# Apply the function to the DataFrame to create the 'id' column\n",
    "new_df['id'] = new_df.apply(generate_id, axis=1, fields=id_fields)\n",
    "\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "# En el caso de tener un df en Bigquery, lo leemos y guardamos solo los nuevos registros\n",
    "try:\n",
    "    # Filtramos solamente los nuevos registros\n",
    "    df_incremental = bigquery.select_for_incremental(id='id', table=table_conca, new_df=new_df)\n",
    "\n",
    "    # Guardamos los datos en bigquery\n",
    "    bigquery.save_dataframe(df_incremental, project, dataset, table, if_exists='append', schema=None)\n",
    "\n",
    "# En el caso de no tener datos en Bigquery, guardamos todo el df\n",
    "except:\n",
    "    bigquery.save_dataframe(new_df, project, dataset, table, if_exists='append', schema=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "financialkeepcoders",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
