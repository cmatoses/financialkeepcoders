{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from google.cloud import bigquery\n",
    "from google.oauth2 import service_account\n",
    "from google.cloud import bigquery\n",
    "from google.cloud.exceptions import NotFound\n",
    "import pandas as pd\n",
    "from utils.utils_bigquery import *\n",
    "from datetime import *\n",
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "import numpy as np\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_path = key_path\n",
    "project = project_id\n",
    "\n",
    "# Sources\n",
    "table = 'silver_indicators'\n",
    "dataset = 'silver'\n",
    "\n",
    "# Tables id\n",
    "table_conca = f'{project}.{dataset}.{table}'\n",
    "\n",
    "# Loading tables\n",
    "table_to_save = 'silver_news_data'\n",
    "dataset_to_save = 'silver'\n",
    "table_conca_to_save = f'{project}.{dataset_to_save}.{table_to_save}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conectamos con Bigquery\n",
    "bigquery = BigQueryUtils(key_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PCAR</td>\n",
       "      <td>2018-07-12 00:00:00+00:00</td>\n",
       "      <td>41.066666</td>\n",
       "      <td>41.153332</td>\n",
       "      <td>1613550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PCAR</td>\n",
       "      <td>2020-07-28 00:00:00+00:00</td>\n",
       "      <td>57.313332</td>\n",
       "      <td>56.966667</td>\n",
       "      <td>2995650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PCAR</td>\n",
       "      <td>2018-05-25 00:00:00+00:00</td>\n",
       "      <td>43.433334</td>\n",
       "      <td>43.093334</td>\n",
       "      <td>1427250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EQIX</td>\n",
       "      <td>2021-06-25 00:00:00+00:00</td>\n",
       "      <td>780.190002</td>\n",
       "      <td>783.400024</td>\n",
       "      <td>1128500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TRMB</td>\n",
       "      <td>2022-06-03 00:00:00+00:00</td>\n",
       "      <td>69.120003</td>\n",
       "      <td>68.629997</td>\n",
       "      <td>746900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7821003</th>\n",
       "      <td>SUSC</td>\n",
       "      <td>2017-11-27 00:00:00+00:00</td>\n",
       "      <td>25.434999</td>\n",
       "      <td>25.434999</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7821004</th>\n",
       "      <td>THRY</td>\n",
       "      <td>2019-06-05 00:00:00+00:00</td>\n",
       "      <td>10.675000</td>\n",
       "      <td>10.675000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7821005</th>\n",
       "      <td>SMCP</td>\n",
       "      <td>2017-08-07 00:00:00+00:00</td>\n",
       "      <td>24.160000</td>\n",
       "      <td>24.160000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7821006</th>\n",
       "      <td>ENVB</td>\n",
       "      <td>2015-08-04 00:00:00+00:00</td>\n",
       "      <td>17600.000000</td>\n",
       "      <td>17550.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7821007</th>\n",
       "      <td>KPRX</td>\n",
       "      <td>2015-03-17 00:00:00+00:00</td>\n",
       "      <td>27000.000000</td>\n",
       "      <td>24300.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7821008 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ticker                      date          open         close   volume\n",
       "0         PCAR 2018-07-12 00:00:00+00:00     41.066666     41.153332  1613550\n",
       "1         PCAR 2020-07-28 00:00:00+00:00     57.313332     56.966667  2995650\n",
       "2         PCAR 2018-05-25 00:00:00+00:00     43.433334     43.093334  1427250\n",
       "3         EQIX 2021-06-25 00:00:00+00:00    780.190002    783.400024  1128500\n",
       "4         TRMB 2022-06-03 00:00:00+00:00     69.120003     68.629997   746900\n",
       "...        ...                       ...           ...           ...      ...\n",
       "7821003   SUSC 2017-11-27 00:00:00+00:00     25.434999     25.434999        0\n",
       "7821004   THRY 2019-06-05 00:00:00+00:00     10.675000     10.675000        0\n",
       "7821005   SMCP 2017-08-07 00:00:00+00:00     24.160000     24.160000        0\n",
       "7821006   ENVB 2015-08-04 00:00:00+00:00  17600.000000  17550.000000        0\n",
       "7821007   KPRX 2015-03-17 00:00:00+00:00  27000.000000  24300.000000        0\n",
       "\n",
       "[7821008 rows x 5 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tickers_data = bigquery.run_query(\n",
    "    f\"\"\"\n",
    "    SELECT\n",
    "        ticker,\n",
    "        date,\n",
    "        open,\n",
    "        close,\n",
    "        volume\n",
    "    FROM {project}.{dataset}.{table}\n",
    "    \"\"\"\n",
    ")\n",
    "tickers_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 61\u001b[0m\n\u001b[0;32m     52\u001b[0m         news\u001b[38;5;241m.\u001b[39mappend({\n\u001b[0;32m     53\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mticker\u001b[39m\u001b[38;5;124m'\u001b[39m: ticker,\n\u001b[0;32m     54\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m: date,\n\u001b[0;32m     55\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtitles\u001b[39m\u001b[38;5;124m'\u001b[39m: titles\n\u001b[0;32m     56\u001b[0m         })\n\u001b[0;32m     58\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m news\n\u001b[1;32m---> 61\u001b[0m news \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_news_titles\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtickers_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     62\u001b[0m news\n",
      "Cell \u001b[1;32mIn[11], line 25\u001b[0m, in \u001b[0;36mgenerate_news_titles\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m     22\u001b[0m market_factors \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mearnings expectations\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124manalyst reports\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mindustry news\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtechnological advancements\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     24\u001b[0m grouped \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mgroupby([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mticker\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m---> 25\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (ticker, date), group \u001b[38;5;129;01min\u001b[39;00m grouped:\n\u001b[0;32m     26\u001b[0m     row \u001b[38;5;241m=\u001b[39m group\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     27\u001b[0m     price_change \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclose\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m-\u001b[39m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mopen\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\CARLES\\anaconda3\\envs\\financialkeepcoders\\lib\\site-packages\\pandas\\core\\groupby\\ops.py:727\u001b[0m, in \u001b[0;36mBaseGrouper.get_iterator\u001b[1;34m(self, data, axis)\u001b[0m\n\u001b[0;32m    725\u001b[0m splitter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_splitter(data, axis\u001b[38;5;241m=\u001b[39maxis)\n\u001b[0;32m    726\u001b[0m keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroup_keys_seq\n\u001b[1;32m--> 727\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(keys, splitter)\n",
      "File \u001b[1;32mc:\\Users\\CARLES\\anaconda3\\envs\\financialkeepcoders\\lib\\site-packages\\pandas\\core\\groupby\\ops.py:1239\u001b[0m, in \u001b[0;36mDataSplitter.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1236\u001b[0m starts, ends \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39mgenerate_slices(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slabels, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mngroups)\n\u001b[0;32m   1238\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m start, end \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(starts, ends):\n\u001b[1;32m-> 1239\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_chop\u001b[49m\u001b[43m(\u001b[49m\u001b[43msdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mslice\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\CARLES\\anaconda3\\envs\\financialkeepcoders\\lib\\site-packages\\pandas\\core\\groupby\\ops.py:1264\u001b[0m, in \u001b[0;36mFrameSplitter._chop\u001b[1;34m(self, sdata, slice_obj)\u001b[0m\n\u001b[0;32m   1258\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_chop\u001b[39m(\u001b[38;5;28mself\u001b[39m, sdata: DataFrame, slice_obj: \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[0;32m   1259\u001b[0m     \u001b[38;5;66;03m# Fastpath equivalent to:\u001b[39;00m\n\u001b[0;32m   1260\u001b[0m     \u001b[38;5;66;03m# if self.axis == 0:\u001b[39;00m\n\u001b[0;32m   1261\u001b[0m     \u001b[38;5;66;03m#     return sdata.iloc[slice_obj]\u001b[39;00m\n\u001b[0;32m   1262\u001b[0m     \u001b[38;5;66;03m# else:\u001b[39;00m\n\u001b[0;32m   1263\u001b[0m     \u001b[38;5;66;03m#     return sdata.iloc[:, slice_obj]\u001b[39;00m\n\u001b[1;32m-> 1264\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[43msdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_slice\u001b[49m\u001b[43m(\u001b[49m\u001b[43mslice_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1265\u001b[0m     df \u001b[38;5;241m=\u001b[39m sdata\u001b[38;5;241m.\u001b[39m_constructor(mgr)\n\u001b[0;32m   1266\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df\u001b[38;5;241m.\u001b[39m__finalize__(sdata, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgroupby\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "# Generamos sinÃ³nimos\n",
    "def get_synonyms(word, pos):\n",
    "    synsets = wn.synsets(word, pos=pos)\n",
    "    return list(set([lemma.name() for synset in synsets for lemma in synset.lemmas()]))\n",
    "\n",
    "\n",
    "def generate_news_titles(df):\n",
    "    news = []\n",
    "    \n",
    "    templates = [\n",
    "        \"{ticker} stock {movement} {percent}% as {market_condition}\",\n",
    "        \"Investors {reaction} as {ticker} shares {movement} ${price_change}\",\n",
    "        \"{ticker} {performance} in {volume} trading session\",\n",
    "        \"{market_condition} leads to {movement} in {ticker} stock\",\n",
    "        \"{ticker} shares {movement} amid {market_factor}\"\n",
    "    ]\n",
    "    \n",
    "    market_conditions = ['market volatility', 'economic uncertainty', 'sector trends', 'global factors']\n",
    "    market_factors = ['earnings expectations', 'analyst reports', 'industry news', 'technological advancements']\n",
    "    \n",
    "    grouped = df.groupby(['ticker', 'date'])\n",
    "    for (ticker, date), group in grouped:\n",
    "        row = group.iloc[0]\n",
    "        price_change = row['close'] - row['open']\n",
    "        percent_change = (price_change / row['open']) * 100\n",
    "        volume_change = row['volume'] - group['volume'].mean()\n",
    "        \n",
    "        movement_words = get_synonyms('increase', 'v') if price_change > 0 else get_synonyms('decrease', 'v')\n",
    "        reaction_words = get_synonyms('optimistic', 'a') if price_change > 0 else get_synonyms('pessimistic', 'a')\n",
    "        performance_words = get_synonyms('excel', 'v') if price_change > 0 else get_synonyms('struggle', 'v')\n",
    "        volume_words = ['high-volume', 'active', 'busy'] if volume_change > 0 else ['low-volume', 'quiet', 'subdued']\n",
    "        \n",
    "        num_titles = random.randint(3, 6)\n",
    "        titles = []\n",
    "        for _ in range(num_titles):\n",
    "            headline = random.choice(templates).format(\n",
    "                ticker=ticker,\n",
    "                movement=random.choice(movement_words).replace('_', ' '),\n",
    "                percent=abs(round(percent_change, 2)),\n",
    "                price_change=abs(round(price_change, 2)),\n",
    "                market_condition=random.choice(market_conditions),\n",
    "                reaction=random.choice(reaction_words).replace('_', ' '),\n",
    "                performance=random.choice(performance_words).replace('_', ' '),\n",
    "                volume=random.choice(volume_words),\n",
    "                market_factor=random.choice(market_factors)\n",
    "            )\n",
    "            titles.append(headline)\n",
    "        \n",
    "        news.append({\n",
    "            'ticker': ticker,\n",
    "            'date': date,\n",
    "            'titles': titles\n",
    "        })\n",
    "    \n",
    "    return news\n",
    "\n",
    "\n",
    "news = generate_news_titles(tickers_data)\n",
    "news\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sentiment Distribution:\n",
      "sentiment\n",
      "NEGATIVE    0.558736\n",
      "NEUTRAL     0.301100\n",
      "POSITIVE    0.140164\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Volvemos a analizar el sentimiento de las noticias sintÃ©ticas creadas\n",
    "\n",
    "text_column = 'News_Title'  \n",
    "\n",
    "def perform_sentiment_analysis(texts):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"ProsusAI/finbert\")\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\"ProsusAI/finbert\")\n",
    "\n",
    "    results = []\n",
    "    for text in texts:\n",
    "        inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512)\n",
    "        outputs = model(**inputs)\n",
    "        probabilities = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "        sentiment_score = probabilities[0][2].item() - probabilities[0][0].item()  # Positive - Negative\n",
    "        results.append(sentiment_score)\n",
    "    \n",
    "    return results\n",
    "\n",
    "sentiment_scores = perform_sentiment_analysis(news[text_column])\n",
    "news['sentiment_score'] = sentiment_scores\n",
    "news['sentiment'] = pd.cut(news['sentiment_score'], \n",
    "                              bins=[-np.inf, -0.05, 0.05, np.inf], \n",
    "                              labels=['NEGATIVE', 'NEUTRAL', 'POSITIVE'])\n",
    "\n",
    "print(\"\\nSentiment Distribution:\")\n",
    "print(news['sentiment'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>News_Title</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-08-26</td>\n",
       "      <td>sector trends leads to increase in Apple stock</td>\n",
       "      <td>-0.891113</td>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-08-26</td>\n",
       "      <td>Investors affirmative as Apple shares increase...</td>\n",
       "      <td>-0.856307</td>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-08-26</td>\n",
       "      <td>Investors affirmative as Apple shares increase...</td>\n",
       "      <td>-0.856307</td>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-08-27</td>\n",
       "      <td>Apple stock fall 1.78% as global factors</td>\n",
       "      <td>0.017897</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-08-27</td>\n",
       "      <td>Apple shares lessen amid earnings expectations</td>\n",
       "      <td>0.011305</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5724</th>\n",
       "      <td>2024-08-22</td>\n",
       "      <td>global factors leads to fall in Apple stock</td>\n",
       "      <td>0.010335</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5725</th>\n",
       "      <td>2024-08-23</td>\n",
       "      <td>Investors optimistic as Apple shares increase ...</td>\n",
       "      <td>-0.882363</td>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5726</th>\n",
       "      <td>2024-08-23</td>\n",
       "      <td>Apple stock increase 0.52% as market volatility</td>\n",
       "      <td>-0.393367</td>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5727</th>\n",
       "      <td>2024-08-23</td>\n",
       "      <td>Apple stand out in quiet trading session</td>\n",
       "      <td>0.633735</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5728</th>\n",
       "      <td>2024-08-23</td>\n",
       "      <td>Apple shares increase amid analyst reports</td>\n",
       "      <td>-0.706012</td>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5729 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date                                         News_Title  \\\n",
       "0     2019-08-26     sector trends leads to increase in Apple stock   \n",
       "1     2019-08-26  Investors affirmative as Apple shares increase...   \n",
       "2     2019-08-26  Investors affirmative as Apple shares increase...   \n",
       "3     2019-08-27           Apple stock fall 1.78% as global factors   \n",
       "4     2019-08-27     Apple shares lessen amid earnings expectations   \n",
       "...          ...                                                ...   \n",
       "5724  2024-08-22        global factors leads to fall in Apple stock   \n",
       "5725  2024-08-23  Investors optimistic as Apple shares increase ...   \n",
       "5726  2024-08-23    Apple stock increase 0.52% as market volatility   \n",
       "5727  2024-08-23           Apple stand out in quiet trading session   \n",
       "5728  2024-08-23         Apple shares increase amid analyst reports   \n",
       "\n",
       "      sentiment_score sentiment  \n",
       "0           -0.891113  NEGATIVE  \n",
       "1           -0.856307  NEGATIVE  \n",
       "2           -0.856307  NEGATIVE  \n",
       "3            0.017897   NEUTRAL  \n",
       "4            0.011305   NEUTRAL  \n",
       "...               ...       ...  \n",
       "5724         0.010335   NEUTRAL  \n",
       "5725        -0.882363  NEGATIVE  \n",
       "5726        -0.393367  NEGATIVE  \n",
       "5727         0.633735  POSITIVE  \n",
       "5728        -0.706012  NEGATIVE  \n",
       "\n",
       "[5729 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_sint = news.groupby('date')\n",
    "\n",
    "agg_sint = pd.DataFrame({\n",
    "        'positive_sentiment': grouped_sint.apply(lambda x: x[x['sentiment'] == 'POSITIVE']['sentiment_score'].mean()),\n",
    "        'negative_sentiment': grouped_sint.apply(lambda x: x[x['sentiment'] == 'NEGATIVE']['sentiment_score'].mean()),\n",
    "        'neutral_sentiment': grouped_sint.apply(lambda x: x[x['sentiment'] == 'NEUTRAL']['sentiment_score'].mean()),\n",
    "        'positive_count': grouped_sint.apply(lambda x: (x['sentiment'] == 'POSITIVE').sum()),\n",
    "        'negative_count': grouped_sint.apply(lambda x: (x['sentiment'] == 'NEGATIVE').sum()),\n",
    "        'neutral_count': grouped_sint.apply(lambda x: (x['sentiment'] == 'NEUTRAL').sum()),\n",
    "        'news_count': grouped_sint.size()\n",
    "    })\n",
    "\n",
    "agg_sint = agg_sint.fillna(0)\n",
    "conditions = [\n",
    "    (agg_sint['positive_count'] > agg_sint['negative_count']) & (agg_sint['neutral_count'] == agg_sint['positive_count']),\n",
    "    (agg_sint['negative_count'] > agg_sint['positive_count']) & (agg_sint['neutral_count'] == agg_sint['negative_count']),\n",
    "    (agg_sint['neutral_count'] > agg_sint['positive_count']) & (agg_sint['neutral_count'] > agg_sint['negative_count']),\n",
    "    (agg_sint['positive_count'] == agg_sint['negative_count']) & (agg_sint['positive_count'] == agg_sint['neutral_count']),\n",
    "    (agg_sint['neutral_count'] == agg_sint['positive_count']) & (agg_sint['positive_count'] > agg_sint['negative_count']),\n",
    "    (agg_sint['neutral_count'] == agg_sint['negative_count']) & (agg_sint['negative_count'] > agg_sint['positive_count']),\n",
    "    (agg_sint['positive_count'] > agg_sint['negative_count']),\n",
    "    (agg_sint['negative_count'] > agg_sint['positive_count'])\n",
    "]\n",
    "\n",
    "choices = [1, -1, 0, 0, 1, -1, 1, -1]\n",
    "agg_sint['sentiment_indicator'] = np.select(conditions, choices, default=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_stock_and_news(stock_df, news_df):\n",
    "    final_df = stock_df.join(news_df, how='left')\n",
    "    final_df.sort_index(inplace=True)\n",
    "    final_df['sentiment_indicator'] = final_df['sentiment_indicator'].ffill()\n",
    "\n",
    "final_df = combine_stock_and_news(tickers_data, agg_sint)\n",
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fields that make up the ID\n",
    "id_fields = ['ticker', 'date']\n",
    "\n",
    "# Apply the function to the DataFrame to create the 'id' column\n",
    "final_df['id'] = final_df.apply(generate_id, axis=1, fields=id_fields)\n",
    "\n",
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No new records to load.\n"
     ]
    }
   ],
   "source": [
    "# try:\n",
    "# Filtramos solamente los nuevos registros\n",
    "df_incremental = bigquery.select_for_incremental(id='id', table=table_conca_to_save, new_df=final_df)\n",
    "\n",
    "if not df_incremental.empty:\n",
    "    # Guardamos los datos en Bigquery\n",
    "    bigquery.save_dataframe(df_incremental, project, dataset_to_save, table_to_save, if_exists='append', schema=None)\n",
    "    print(f'New records loaded')\n",
    "else:\n",
    "    print('No new records to load.')\n",
    "\n",
    "# En el caso de no tener datos en Bigquery, guardamos todo el df\n",
    "# except Exception as e:\n",
    "#     bigquery.save_dataframe(final_df, project, dataset_to_save, table_to_save, if_exists='replace', schema=None)\n",
    "#     print('New data persisted')\n",
    "#     print(f'Exception encountered: {e}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "financialkeepcoders",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
